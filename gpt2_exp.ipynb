{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import kaggle\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"squad\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 87599\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "traindata = dataset['train']\n",
    "print(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87599 87599\n",
      "{'id': '5733be284776f41900661182', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}\n",
      "Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary. 71\n"
     ]
    }
   ],
   "source": [
    "# for d in traindata.features:\n",
    "#     print(d)\n",
    "#     print(traindata[d][:5])\n",
    "#     print()\n",
    "\n",
    "# for d in traindata[\"context\"]:\n",
    "#     print(d)\n",
    "    # print(traindata[d][:5])\n",
    "    # print()\n",
    "\n",
    "print(len(traindata[\"context\"]), len(traindata[\"question\"]))\n",
    "\n",
    "print(traindata[0])\n",
    "\n",
    "print((traindata[0]['context'][515:]), len(traindata[0]['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_max_length \t 1024\n",
      "padding_side \t right\n",
      "truncation_side \t right\n",
      "chat_template \t None\n",
      "model_input_names \t ['input_ids', 'attention_mask']\n",
      "bos_token \t <|endoftext|>\n",
      "eos_token \t <|endoftext|>\n",
      "unk_token \t <|endoftext|>\n",
      "sep_token \t None\n",
      "pad_token \t None\n",
      "cls_token \t None\n",
      "mask_token \t None\n",
      "additional_special_tokens \t []\n",
      "clean_up_tokenization_spaces \t True\n",
      "split_special_tokens \t False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in [\n",
    "    \"model_max_length\",\n",
    "    \"padding_side\",\n",
    "    \"truncation_side\",\n",
    "    \"chat_template\",\n",
    "    \"model_input_names\",\n",
    "    \"bos_token\",\n",
    "    \"eos_token\",\n",
    "    \"unk_token\",\n",
    "    \"sep_token\",\n",
    "    \"pad_token\",\n",
    "    \"cls_token\",\n",
    "    \"mask_token\",\n",
    "    \"additional_special_tokens\",\n",
    "    \"clean_up_tokenization_spaces\",\n",
    "    \"split_special_tokens\",\n",
    "]:\n",
    "    print(k, \"\\t\", tokenizer.__getattribute__(k))\n",
    "\n",
    "tokenizer.add_special_tokens({\"bos_token\": \"<|bos|>\",\n",
    "                              \"eos_token\": \"<|eos|>\",\n",
    "                              \"unk_token\": \"<|unk|>\",\n",
    "                              \"sep_token\": \"<|sep|>\",\n",
    "                              \"pad_token\": \"<|pad|>\",\n",
    "                              \"cls_token\": \"<|cls|>\"})\n",
    "model.resize_token_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  464, 15896,  6766,   427,  8608,  1068,   351,   257,  9814,   395,\n",
       "           563,   286,  5788,    11, 13092,   257, 10296, 19634,   319,   262,\n",
       "         11029,   995,  2174,    13, 50261, 50261, 50261, 50261, 50261],\n",
       "        [   32,  2984,  3043, 31222, 28633, 39480,   832,   262, 23608,  5667,\n",
       "            11,  4441,   257,  5659, 23021,   286, 17000,  1359,  5238,   287,\n",
       "           262,  5897,  8222,    13, 50261, 50261, 50261, 50261, 50261],\n",
       "        [  464, 31242,   286, 29026, 40163,  6891,  2082,   701,   276,   832,\n",
       "           262,  1633,    11, 47460, 45378,  1525,   284, 14985,   290,  6799,\n",
       "           273,   262,  5527, 36860,    13, 50261, 50261, 50261, 50261],\n",
       "        [  818,   262, 46609,  1910,    11, 17192,  1444,   503,   511,  2082,\n",
       "           411,    11,   290, 21266,  7577, 41860, 40308,    11,  4441,   257,\n",
       "         29696,  9814,   395,   563,   286, 21343,   290,  5238,    13]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1]], device='cuda:0'), 'labels': tensor([1, 2, 3, 4], device='cuda:0')}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = [\n",
    "    \"The midnight sky shimmered with a tapestry of stars, casting a gentle glow on the sleeping world below.\",\n",
    "    \"A mischievous breeze danced through the autumn leaves, creating a symphony of rustling sounds in the quiet forest.\",\n",
    "    \"The aroma of freshly brewed coffee wafted through the air, enticing passersby to pause and savor the rich fragrance.\",\n",
    "    \"In the bustling market, vendors called out their wares, and vibrant colors adorned stalls, creating a lively tapestry of sights and sounds.\",\n",
    "]\n",
    "\n",
    "tokens = tokenizer(sequences, padding=True, truncation=True).convert_to_tensors('pt')\n",
    "\n",
    "tokens[\"labels\"] = torch.tensor([1,2,3,4])\n",
    "tokens.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithCrossAttentions(loss=None, logits=tensor([[ -30.6604,  -30.1158,  -33.6834,  ...,  -37.9073,  -38.2578,\n",
       "          -30.8604],\n",
       "        [-107.9952, -108.7846, -115.7549,  ..., -118.2143, -120.6317,\n",
       "         -112.7074],\n",
       "        [ -98.3191,  -96.2061,  -99.8060,  ..., -105.8533, -103.8315,\n",
       "          -98.1554],\n",
       "        [-100.1074, -101.4207, -106.8903,  ..., -114.9794, -115.4330,\n",
       "         -104.4623]], device='cuda:0', grad_fn=<MmBackward0>), past_key_values=((tensor([[[[-1.0222,  1.6269,  0.2036,  ..., -1.7009, -0.3993,  0.7531],\n",
       "          [-2.1670,  2.8019,  2.2601,  ..., -1.4357, -1.5906,  1.6516],\n",
       "          [-2.3145,  2.7101,  1.5073,  ..., -0.5781, -1.9292,  2.2634],\n",
       "          [-1.4637,  2.9009,  1.4456,  ..., -0.6122, -0.8635,  1.7498]],\n",
       "\n",
       "         [[-0.4341, -0.0548, -0.1414,  ...,  0.0536,  2.6886,  1.7793],\n",
       "          [-1.2517, -2.9653, -3.7894,  ..., -1.2439,  3.2664, -0.1477],\n",
       "          [-0.7140, -1.6105, -2.9748,  ..., -1.6920,  4.4462,  0.1892],\n",
       "          [-1.0916, -2.5367,  0.7504,  ...,  1.0381,  4.7576,  1.5449]],\n",
       "\n",
       "         [[-0.3009, -0.2655,  1.2803,  ..., -1.1718, -1.7620,  0.7597],\n",
       "          [ 0.3523,  0.9841,  0.2493,  ..., -2.8993,  0.0526,  1.3950],\n",
       "          [ 0.3226, -0.0288,  0.3313,  ..., -3.1311,  0.2430,  1.3300],\n",
       "          [ 0.6608,  0.5811,  0.4083,  ..., -3.4818,  0.7544,  1.4306]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.3871, -0.3024, -0.3093,  ...,  0.3702,  0.6061,  0.3612],\n",
       "          [ 0.3601,  0.0934,  0.1340,  ...,  0.9407,  0.8990,  0.0982],\n",
       "          [-0.0874, -0.1036, -0.0071,  ...,  1.2412,  0.6223,  0.4742],\n",
       "          [-0.2785,  0.4899,  1.1290,  ...,  1.6367,  0.5966,  0.1130]],\n",
       "\n",
       "         [[ 1.3732,  0.9871, -0.4885,  ...,  0.0377,  1.4455, -0.8367],\n",
       "          [ 0.7040,  0.3636, -0.5809,  ..., -1.7093,  1.5637, -0.2750],\n",
       "          [ 0.9876,  0.8250, -0.1679,  ..., -1.2784,  0.9794, -1.0050],\n",
       "          [ 0.4017, -0.1789, -0.2609,  ..., -0.7216,  0.6921,  0.3760]],\n",
       "\n",
       "         [[ 0.6918,  0.1143,  0.2445,  ..., -0.2988,  0.2417,  2.0894],\n",
       "          [ 0.5403,  0.9768,  0.1606,  ...,  0.2130,  0.2924,  2.2358],\n",
       "          [-0.1124,  1.0617,  0.0329,  ...,  0.2203,  0.6739,  1.2803],\n",
       "          [ 0.0697, -1.1299, -0.1844,  ...,  0.3064,  0.1272,  0.3761]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>), tensor([[[[ 1.5571e-01,  1.3104e-02, -1.1616e-01,  ...,  1.2427e-01,\n",
       "            1.2540e-02,  3.8663e-02],\n",
       "          [ 1.2030e-01,  4.5757e-02,  2.6542e-02,  ...,  9.6176e-02,\n",
       "            1.7225e-01, -4.2050e-02],\n",
       "          [-4.9511e-02,  7.4071e-03, -2.8154e-02,  ...,  1.2485e-01,\n",
       "           -3.5409e-02, -7.5963e-02],\n",
       "          [ 2.1647e-01, -2.4088e-01,  1.3609e-01,  ...,  1.9030e-01,\n",
       "           -4.7608e-02, -1.3960e-01]],\n",
       "\n",
       "         [[ 4.2403e-01,  1.2370e-01, -3.4973e-01,  ..., -5.0183e-01,\n",
       "           -4.9856e-01,  1.1355e-01],\n",
       "          [ 4.6198e-01, -2.6301e-01,  1.7619e-02,  ...,  2.4264e-01,\n",
       "            1.9191e-01, -1.3087e-01],\n",
       "          [ 7.6954e-01, -1.2836e-01,  3.4602e-01,  ..., -1.1713e-01,\n",
       "            3.3321e-01,  1.3056e-01],\n",
       "          [ 1.2552e-01, -2.1878e-01, -1.8098e-01,  ...,  2.2478e-01,\n",
       "           -3.6642e-01,  3.9801e-03]],\n",
       "\n",
       "         [[ 2.1590e-01, -5.6876e-02,  3.0244e-02,  ...,  7.4424e-02,\n",
       "            1.1711e-02, -1.4122e-01],\n",
       "          [-3.2926e-01, -1.1394e-01, -3.8316e-01,  ..., -4.0445e-01,\n",
       "           -3.4879e-01, -1.0690e-02],\n",
       "          [-4.1603e-01, -3.7761e-02, -5.1928e-01,  ..., -1.2976e-01,\n",
       "           -9.8224e-02,  2.0073e-01],\n",
       "          [ 1.8714e-01, -1.7571e-02,  2.7744e-02,  ...,  7.5740e-04,\n",
       "            1.0596e-01, -5.5101e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.2262e-01,  5.8634e-02,  2.0126e-02,  ...,  6.7751e-02,\n",
       "            5.3466e-02, -1.1929e-01],\n",
       "          [-1.4451e-01,  3.2664e-01,  6.4184e-02,  ..., -1.1662e-01,\n",
       "           -2.6791e-01,  2.4427e-01],\n",
       "          [-1.4000e-01, -1.9747e-01, -1.0718e-01,  ...,  1.7734e-01,\n",
       "           -2.0112e-01,  4.0236e-01],\n",
       "          [-1.3812e-01,  7.6524e-02, -3.4943e-01,  ...,  9.7970e-02,\n",
       "           -1.7467e-02,  3.4062e-02]],\n",
       "\n",
       "         [[ 1.9423e-01, -1.3629e-01, -1.8858e-01,  ...,  1.7966e-02,\n",
       "            1.8727e-01,  1.0188e-01],\n",
       "          [-7.7099e-02, -1.0494e-01,  1.5973e-01,  ..., -4.1184e-01,\n",
       "           -3.1722e-02,  1.7386e-01],\n",
       "          [-2.1430e-01,  7.4153e-02, -1.3433e-01,  ...,  2.8439e-01,\n",
       "            4.4380e-02, -1.0576e-01],\n",
       "          [-7.2806e-02, -1.2166e-01,  3.3132e-02,  ..., -2.8064e-01,\n",
       "            8.1424e-02,  1.7585e-01]],\n",
       "\n",
       "         [[-1.2831e-01, -3.2557e-01,  2.2015e-01,  ..., -1.9842e-02,\n",
       "           -9.5558e-02, -3.7909e-02],\n",
       "          [-1.3361e-01, -3.6345e-03, -2.4693e-01,  ..., -6.1865e-02,\n",
       "            1.3640e-01,  2.1244e-01],\n",
       "          [-8.7157e-02, -1.6566e-02, -7.1012e-02,  ...,  1.6309e-01,\n",
       "            3.8762e-02,  3.1650e-02],\n",
       "          [-9.1335e-02, -1.9366e-02, -1.2828e-01,  ..., -2.2168e-01,\n",
       "           -2.7649e-01, -2.6731e-02]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-4.6057e-03,  1.8449e+00, -1.9886e+00,  ...,  1.2745e+00,\n",
       "           -1.7312e+00,  6.2379e-01],\n",
       "          [ 1.7776e+00,  2.0449e+00, -1.4074e+00,  ..., -2.9229e-01,\n",
       "           -2.3219e+00,  1.7305e-01],\n",
       "          [ 8.2544e-01,  1.6501e+00, -1.0758e+00,  ...,  1.6090e-03,\n",
       "           -1.5834e+00, -8.4010e-02],\n",
       "          [ 1.3767e+00,  1.6768e+00,  1.2936e-01,  ...,  2.8846e-01,\n",
       "           -2.2155e+00,  1.4738e-01]],\n",
       "\n",
       "         [[-1.0625e+00, -1.3939e-01, -5.4713e-01,  ..., -8.5422e-02,\n",
       "            9.4508e-01, -2.3212e-01],\n",
       "          [-5.4254e-01,  3.3995e-02, -1.3331e+00,  ..., -2.0093e-01,\n",
       "            3.9168e-01,  6.2598e-01],\n",
       "          [-9.8410e-01,  4.7129e-02, -1.1917e+00,  ..., -1.0563e+00,\n",
       "            2.6759e-01, -2.6985e-01],\n",
       "          [-1.3698e-01,  3.7770e-01, -1.6083e+00,  ..., -5.1064e-01,\n",
       "           -3.4729e-01, -3.1194e-01]],\n",
       "\n",
       "         [[ 5.4143e-01,  1.7962e-01, -9.4702e-02,  ..., -1.3281e+00,\n",
       "            2.4593e-01, -2.1923e-01],\n",
       "          [-1.1331e-01,  5.1103e-01, -3.2105e-02,  ..., -9.4710e-01,\n",
       "           -3.3488e-01,  5.7622e-01],\n",
       "          [-1.7431e-01, -7.8216e-02, -8.1840e-02,  ..., -8.1681e-01,\n",
       "            1.2039e-01,  2.6097e-01],\n",
       "          [ 2.9660e-02,  1.0786e-01, -5.5137e-02,  ..., -1.2098e+00,\n",
       "            3.9057e-02,  5.4163e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.5933e-01, -4.5893e-01, -4.7021e-01,  ..., -1.1877e+00,\n",
       "            7.0441e-01, -6.0522e-01],\n",
       "          [ 3.6339e-01,  1.1396e+00,  1.4198e+00,  ...,  1.8546e+00,\n",
       "            5.0770e-01, -5.6301e-01],\n",
       "          [-6.1189e-01,  8.9499e-01,  1.0515e+00,  ..., -7.8006e-01,\n",
       "            1.2651e+00, -7.5683e-01],\n",
       "          [-2.3709e+00,  7.5124e-01,  1.7637e+00,  ..., -2.2728e-01,\n",
       "            5.2562e-01,  8.2966e-01]],\n",
       "\n",
       "         [[-1.2373e+00, -2.7131e+00,  1.3630e-01,  ...,  1.7827e+00,\n",
       "            1.6556e+00, -1.5138e+00],\n",
       "          [ 3.3416e-01,  1.0130e+00, -3.6171e-01,  ..., -8.5875e-01,\n",
       "            4.7286e-01, -1.4217e-01],\n",
       "          [ 3.9587e-01,  4.6169e-01, -4.7530e-01,  ..., -4.5318e-01,\n",
       "            4.8185e-01, -3.3594e-01],\n",
       "          [-1.7044e-01,  5.8693e-01, -4.2959e-01,  ..., -3.9949e-01,\n",
       "            6.2477e-01,  1.3871e-01]],\n",
       "\n",
       "         [[ 5.5179e-01,  2.0190e+00,  9.9991e-01,  ..., -7.2035e-01,\n",
       "           -6.1704e-01,  2.9259e-02],\n",
       "          [ 2.8823e-01,  3.0246e+00,  1.5739e+00,  ...,  1.4812e+00,\n",
       "           -2.0523e-01, -1.0344e+00],\n",
       "          [ 6.4644e-01,  2.4123e+00,  8.6081e-01,  ...,  1.0190e+00,\n",
       "           -1.3832e+00,  2.6704e-01],\n",
       "          [-1.1407e+00,  2.4129e+00,  1.3480e-01,  ...,  2.5115e+00,\n",
       "           -8.4315e-01,  2.9170e-02]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 4.8966e-01,  1.1165e-01,  7.6198e-02,  ..., -1.5060e-02,\n",
       "            1.9784e-01, -2.3449e-02],\n",
       "          [ 2.1063e-01,  1.0429e-01, -3.6042e-01,  ..., -5.0031e-01,\n",
       "            2.0568e-01, -4.9753e-02],\n",
       "          [-1.6723e-01,  9.0599e-01, -3.8845e-01,  ...,  2.4124e-01,\n",
       "           -4.4560e-01,  1.4159e-01],\n",
       "          [ 3.5631e-01, -3.7145e-01, -1.0090e-01,  ..., -4.0951e-01,\n",
       "            5.3801e-01, -1.4895e-01]],\n",
       "\n",
       "         [[-1.4240e-01, -4.4590e-01,  7.2793e-03,  ..., -1.6133e-01,\n",
       "           -4.4697e-01, -1.9469e-01],\n",
       "          [-1.7211e-01,  3.0852e-01, -2.2502e-01,  ...,  9.5722e-02,\n",
       "            1.7709e-02, -2.8763e-01],\n",
       "          [-1.7231e-01,  3.2979e-01,  4.6663e-01,  ...,  6.7819e-02,\n",
       "            1.0052e+00,  3.5231e-01],\n",
       "          [ 7.1631e-01,  1.2296e-01, -2.5470e-01,  ..., -3.5828e-01,\n",
       "           -2.1238e-01, -3.2965e-01]],\n",
       "\n",
       "         [[ 1.4122e-01, -2.9205e-01, -1.9745e-02,  ..., -4.9444e-01,\n",
       "           -7.3948e-03, -1.0870e-01],\n",
       "          [ 5.2186e-01,  1.1417e-01,  5.9337e-01,  ..., -6.1965e-01,\n",
       "            3.5654e-01,  4.1478e-01],\n",
       "          [ 3.7114e-01,  1.0568e-01, -1.0126e-02,  ..., -6.9994e-01,\n",
       "           -6.2017e-02,  1.4044e-02],\n",
       "          [ 7.6374e-01,  1.3395e-01, -1.1773e-01,  ..., -5.0553e-01,\n",
       "           -2.9663e-01,  8.1671e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.2596e-04,  5.8557e-01, -6.3325e-02,  ..., -4.4365e-02,\n",
       "           -1.0926e+00,  2.7058e-01],\n",
       "          [-2.9793e-01,  1.6514e-01,  4.1000e-01,  ..., -8.7678e-02,\n",
       "           -6.9255e-01, -4.4663e-01],\n",
       "          [ 5.1095e-02,  1.8547e-01,  2.2429e-01,  ...,  1.8252e-01,\n",
       "           -5.3687e-01, -3.6562e-01],\n",
       "          [ 1.5249e-02,  2.8909e-02,  6.7081e-01,  ...,  4.5319e-01,\n",
       "           -8.2408e-01,  1.2297e-01]],\n",
       "\n",
       "         [[-3.4008e-02, -5.5416e-02, -2.8749e-01,  ...,  3.5594e-01,\n",
       "           -3.6960e+00,  1.3005e-01],\n",
       "          [ 1.3582e-01, -9.9432e-03,  3.1001e-01,  ...,  4.8339e-01,\n",
       "            6.7151e-02, -2.3600e-01],\n",
       "          [ 1.6900e-02, -2.0279e-01,  2.0292e-01,  ..., -1.5493e-01,\n",
       "            7.9252e-02, -2.6145e-01],\n",
       "          [-3.0422e-01,  1.2226e-01, -2.6374e-02,  ...,  3.3866e-01,\n",
       "            1.4017e-01, -2.2002e-01]],\n",
       "\n",
       "         [[ 4.3513e-02, -1.5136e-01,  6.8532e-02,  ..., -2.2273e-01,\n",
       "            1.2011e-01, -1.3771e-01],\n",
       "          [ 3.5268e-01, -2.6267e-01,  2.1657e-02,  ...,  1.9903e-01,\n",
       "           -2.5578e-02,  2.0590e-01],\n",
       "          [ 1.0596e-01,  1.7001e-01, -2.0110e-01,  ...,  3.2285e-02,\n",
       "            1.2101e-01,  3.0417e-01],\n",
       "          [ 2.2660e-01,  2.7026e-01,  1.9203e-01,  ..., -1.6807e-02,\n",
       "           -8.2408e-02,  8.6012e-02]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-1.5255e-01, -1.0701e+00,  2.7252e-01,  ..., -6.7378e-01,\n",
       "           -1.2578e-01, -2.2091e-02],\n",
       "          [ 7.4713e-01, -2.4198e+00,  2.6595e-01,  ...,  1.0541e-01,\n",
       "            3.5876e-01,  1.0013e-02],\n",
       "          [-2.1331e-03, -1.6315e+00, -9.2678e-01,  ..., -8.7579e-02,\n",
       "            3.4699e-01, -4.7640e-01],\n",
       "          [ 4.2358e-02, -3.7321e+00, -5.8541e-01,  ..., -7.2639e-01,\n",
       "            1.3435e+00,  4.7795e-01]],\n",
       "\n",
       "         [[-4.5405e-01,  3.3528e-01, -5.1803e-01,  ...,  1.1901e+00,\n",
       "           -5.3389e-01, -4.6642e-01],\n",
       "          [-1.7087e+00, -5.7375e-01, -1.4771e+00,  ...,  6.9470e-02,\n",
       "            9.5765e-01, -6.3281e-01],\n",
       "          [-1.6084e+00,  1.9533e-01, -5.6216e-01,  ...,  1.2242e-01,\n",
       "            5.3487e-01,  1.6081e+00],\n",
       "          [-1.0711e+00, -1.2559e+00, -7.5482e-01,  ..., -4.2995e-01,\n",
       "           -9.4340e-02, -5.3440e-01]],\n",
       "\n",
       "         [[ 1.2886e+00,  3.0418e+00,  3.7647e+00,  ...,  6.1335e-01,\n",
       "            1.7167e+00, -7.4190e-01],\n",
       "          [-2.7069e+00,  2.1038e+00, -2.3213e+00,  ..., -2.1845e+00,\n",
       "            2.9771e+00,  8.2295e-01],\n",
       "          [-4.0974e+00,  3.0018e-01, -2.3663e+00,  ..., -3.8442e+00,\n",
       "            3.5563e+00, -4.7406e-02],\n",
       "          [-3.3059e+00,  4.4907e-01, -3.4801e+00,  ..., -3.9894e+00,\n",
       "            2.4808e+00,  7.9774e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.3406e+00, -2.7046e+00, -2.5419e+00,  ...,  9.3765e-01,\n",
       "            4.4277e-01,  2.6862e+00],\n",
       "          [-2.7866e+00,  1.9468e+00,  7.7000e-01,  ..., -1.4986e-01,\n",
       "           -2.1601e+00, -2.3880e-02],\n",
       "          [-2.9191e+00,  1.7516e+00, -5.3498e-01,  ...,  1.6551e-01,\n",
       "           -3.1651e+00, -8.5252e-03],\n",
       "          [-2.6279e+00,  2.5914e+00,  7.0924e-01,  ..., -1.1625e+00,\n",
       "           -2.8248e+00, -9.5172e-01]],\n",
       "\n",
       "         [[ 1.7171e+00,  4.6752e-01,  9.1025e-01,  ..., -2.4881e-04,\n",
       "           -1.0012e+00, -3.0085e-01],\n",
       "          [ 1.7229e+00,  1.0896e+00,  1.0786e+00,  ...,  2.1048e-01,\n",
       "           -1.8623e+00, -1.4511e+00],\n",
       "          [ 2.0357e+00,  7.8803e-01,  9.4854e-01,  ...,  4.5646e-01,\n",
       "           -2.4796e+00, -1.5451e+00],\n",
       "          [ 2.4483e+00,  7.8960e-01,  1.2059e+00,  ...,  6.1125e-01,\n",
       "           -1.5448e+00, -5.5020e-01]],\n",
       "\n",
       "         [[-2.6141e-01,  1.5553e-01, -5.6378e-01,  ...,  3.4123e-01,\n",
       "            2.5221e-01,  1.9718e-01],\n",
       "          [-6.9825e-01,  1.0800e+00,  1.0146e-01,  ...,  4.4776e-01,\n",
       "            5.5939e-01,  6.3332e-01],\n",
       "          [ 1.0931e-01,  3.8895e-01, -1.7598e-01,  ..., -5.6443e-02,\n",
       "            9.5681e-03,  5.8294e-01],\n",
       "          [-8.3413e-01,  3.0292e-01, -2.4611e-01,  ..., -1.9962e-02,\n",
       "            8.6394e-01,  8.9847e-02]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-2.9082e-02, -1.3724e-02, -1.4281e-01,  ..., -5.0684e-02,\n",
       "            4.7514e-03, -5.5247e-01],\n",
       "          [ 3.6805e-01, -1.4157e-01, -8.0584e-01,  ..., -6.0805e-01,\n",
       "           -4.0555e-01,  8.3056e-01],\n",
       "          [ 5.1885e-01,  7.0360e-01, -6.3747e-02,  ..., -2.2935e-01,\n",
       "           -1.4435e-01,  9.4532e-01],\n",
       "          [-4.3269e-01, -9.8619e-01,  8.1838e-01,  ..., -7.5460e-01,\n",
       "            3.0965e-01,  8.8987e-01]],\n",
       "\n",
       "         [[ 5.5688e-02, -4.2835e-02, -4.3704e-03,  ..., -4.3340e-02,\n",
       "           -1.4333e-03,  5.6857e-02],\n",
       "          [-3.3313e-01, -2.2406e-01, -1.2257e+00,  ..., -2.3761e-01,\n",
       "            1.5788e-01,  2.4685e-01],\n",
       "          [-2.1709e-01, -8.2772e-02,  6.3405e-02,  ..., -1.4009e-01,\n",
       "            6.8068e-03,  2.5060e-01],\n",
       "          [ 4.8023e-01,  7.9198e-01,  8.5286e-01,  ...,  1.0001e+00,\n",
       "            5.7347e-01, -2.3286e-01]],\n",
       "\n",
       "         [[ 4.2749e-02, -7.4891e-01, -2.7030e-02,  ...,  3.1745e-02,\n",
       "            2.3862e-02, -5.2900e-02],\n",
       "          [-3.0048e-01, -1.2372e+00,  2.5216e-01,  ..., -1.0123e-01,\n",
       "           -5.3210e-02,  1.4433e-01],\n",
       "          [-3.6133e-02, -1.5225e+00,  2.3721e-01,  ...,  2.1909e-01,\n",
       "           -2.3595e-01,  3.2146e-01],\n",
       "          [ 3.5348e-01, -2.1238e+00, -6.9927e-01,  ...,  3.1800e-02,\n",
       "            9.0042e-02, -1.1473e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.4916e-02, -1.0157e-01,  1.3249e+00,  ..., -1.2121e-02,\n",
       "            1.8205e-01, -9.2609e-03],\n",
       "          [-2.4151e-01, -2.6332e-01,  2.0959e+00,  ...,  2.9034e-01,\n",
       "           -8.3513e-04,  6.5728e-01],\n",
       "          [ 3.6910e-01,  6.8363e-01,  2.6383e+00,  ...,  4.1582e-02,\n",
       "            4.6033e-01,  6.6696e-02],\n",
       "          [-5.7042e-01, -1.1382e+00,  1.5713e+00,  ..., -3.1397e-02,\n",
       "           -1.8216e-01,  1.6758e-01]],\n",
       "\n",
       "         [[-8.8220e-03, -1.0999e-01, -1.2361e-01,  ...,  1.8336e-01,\n",
       "            8.7339e-02,  1.9028e-01],\n",
       "          [ 4.6407e-01, -3.8042e-01,  2.9873e-01,  ...,  1.6614e-01,\n",
       "           -5.7973e-01, -5.1685e-01],\n",
       "          [ 4.9927e-02, -1.0718e-01, -1.3800e-01,  ...,  1.2245e-01,\n",
       "           -2.6384e-01, -1.6365e-01],\n",
       "          [ 4.2949e-01, -2.4468e-01,  1.5900e-01,  ...,  5.1128e-02,\n",
       "           -6.4353e-01, -5.5355e-01]],\n",
       "\n",
       "         [[ 7.8201e-03,  1.8019e-02,  4.9397e-02,  ..., -2.2865e-02,\n",
       "            2.0547e-01,  3.3007e-02],\n",
       "          [-6.1366e-01, -1.7501e-01,  3.3619e-01,  ..., -7.6848e-01,\n",
       "           -2.0795e+00, -4.0354e-02],\n",
       "          [ 1.8185e-01, -6.7585e-01,  9.5224e-02,  ..., -4.1872e-01,\n",
       "           -2.1515e+00, -1.5384e-02],\n",
       "          [ 3.3574e-02, -1.0967e-02, -3.4165e-01,  ..., -3.7476e-01,\n",
       "           -2.3204e+00, -2.8002e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.0185, -0.2176,  0.1655,  ..., -0.8859,  0.7298, -1.2074],\n",
       "          [-1.4071, -0.7119, -1.2803,  ..., -0.2805,  0.3445,  0.3556],\n",
       "          [-0.7877,  0.5554, -0.9166,  ..., -1.2750, -1.4138,  0.7744],\n",
       "          [ 0.0384, -1.4603,  1.5190,  ..., -1.7326, -0.8641,  1.9835]],\n",
       "\n",
       "         [[ 0.7943,  0.1928,  0.0189,  ..., -0.1675, -1.0909, -0.2065],\n",
       "          [-0.5807, -1.6011,  1.5376,  ...,  1.1515,  3.6681,  0.7061],\n",
       "          [ 0.1741, -1.6765, -0.1708,  ...,  0.7268,  6.3013,  1.2356],\n",
       "          [ 1.0701, -1.4677, -0.2081,  ...,  0.0278,  4.7290,  2.1547]],\n",
       "\n",
       "         [[ 0.3297, -0.3534, -0.3354,  ...,  0.3596,  1.4570,  0.2433],\n",
       "          [ 0.2567, -5.3156, -1.5871,  ..., -3.3852, -3.0739, -4.9237],\n",
       "          [-0.4759, -6.8423, -1.5223,  ..., -3.9087, -5.1592, -6.7373],\n",
       "          [-0.8436, -5.1819, -0.7247,  ..., -4.4834, -4.2179, -5.8646]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2253,  1.8018,  0.5360,  ...,  0.2374,  0.4513, -1.6930],\n",
       "          [-0.6287, -5.6104, -0.4174,  ..., -2.1486, -1.1633,  6.5461],\n",
       "          [-0.6987, -6.5965,  0.8872,  ..., -2.4426, -1.8602,  6.7982],\n",
       "          [-0.6111, -3.8500,  0.5102,  ..., -0.8398, -1.6601,  7.8845]],\n",
       "\n",
       "         [[ 0.0520, -0.0361,  0.1495,  ..., -0.0978, -0.0989, -0.1489],\n",
       "          [ 1.3912, -2.1268, -1.4883,  ..., -1.7652, -0.7735, -0.5588],\n",
       "          [ 0.4595, -2.4728, -0.8582,  ..., -0.1685, -0.5218, -0.5558],\n",
       "          [ 0.6770, -0.5778, -1.8889,  ..., -1.2034, -0.4715, -0.7502]],\n",
       "\n",
       "         [[ 0.4009, -0.0737,  1.9109,  ..., -0.2477, -0.2224, -0.9838],\n",
       "          [ 2.2989,  2.5172, -1.2886,  ...,  1.1834,  1.7763,  2.5084],\n",
       "          [ 3.7258,  1.0953, -2.6095,  ...,  0.4161,  2.2921,  3.7292],\n",
       "          [ 1.8699,  1.4914, -2.6013,  ...,  1.1924,  1.4318,  4.9647]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>), tensor([[[[ 3.7454e-02,  5.5573e-02, -2.6680e-03,  ...,  1.4814e-02,\n",
       "            9.7241e-02,  3.2711e-02],\n",
       "          [ 1.7439e-01,  1.4544e-01, -4.1145e-01,  ...,  3.9192e-01,\n",
       "           -1.1134e+00,  2.1280e-01],\n",
       "          [ 3.7129e-01, -4.4552e-01, -3.8389e-01,  ...,  3.8968e-01,\n",
       "           -6.8843e-01, -5.2509e-01],\n",
       "          [ 9.2604e-01, -3.5115e-01,  3.2926e-01,  ..., -2.3752e-01,\n",
       "           -2.5481e-01, -1.6157e+00]],\n",
       "\n",
       "         [[-5.4539e-02, -6.0802e-04,  8.4742e-02,  ..., -5.3328e-02,\n",
       "           -4.2516e-02, -4.5709e-02],\n",
       "          [ 6.0734e-01, -2.3754e-01,  4.4713e-01,  ..., -5.4460e-02,\n",
       "           -9.4236e-03,  6.7829e-01],\n",
       "          [ 2.5799e-01, -3.4256e-01,  3.5587e-01,  ...,  2.9901e-01,\n",
       "            1.7565e-01,  7.7173e-02],\n",
       "          [ 7.7151e-01, -2.9684e-01, -2.1103e-01,  ..., -1.0164e-01,\n",
       "            9.8944e-01, -6.2868e-01]],\n",
       "\n",
       "         [[ 3.0940e-02, -1.0955e-01, -6.6904e-02,  ..., -2.4742e-02,\n",
       "            8.8827e-02, -1.5583e-01],\n",
       "          [-2.9482e-01,  3.7130e-01,  2.4522e-01,  ...,  4.7450e-01,\n",
       "            7.2635e-02, -6.9147e-01],\n",
       "          [-3.9537e-01,  4.7816e-01,  1.2952e+00,  ..., -1.7666e-01,\n",
       "            1.0355e-01,  2.1325e-02],\n",
       "          [ 3.3853e-01, -4.4962e-01,  3.4715e-01,  ..., -3.3323e-01,\n",
       "           -2.5631e-01, -1.2995e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.0272e-02,  1.1845e-01, -8.8268e-03,  ..., -2.8900e-02,\n",
       "            6.4849e-02, -3.9939e-02],\n",
       "          [-1.9913e-01,  1.1382e-01, -2.5389e-01,  ...,  2.8149e-01,\n",
       "            5.0863e-02,  5.9262e-01],\n",
       "          [-1.8950e-01, -8.6924e-02, -3.8738e-01,  ...,  3.2025e-01,\n",
       "            3.2410e-01, -2.5929e-02],\n",
       "          [-5.1928e-01, -1.5900e-01, -6.7549e-01,  ...,  3.6587e-01,\n",
       "           -7.7481e-01, -1.8140e-01]],\n",
       "\n",
       "         [[-1.6434e-01, -1.3095e-01, -7.5186e-02,  ..., -2.4716e-01,\n",
       "           -2.8883e-02, -5.2147e-02],\n",
       "          [ 6.7774e-01, -1.3671e+00, -1.4112e+00,  ..., -3.2958e-01,\n",
       "           -1.4229e-02,  1.6303e+00],\n",
       "          [ 4.7074e-01, -7.1467e-01, -3.8119e-01,  ..., -4.0705e-01,\n",
       "            2.2496e-01, -1.4101e-01],\n",
       "          [ 1.0882e+00, -1.6892e+00,  4.9523e-01,  ..., -3.2620e-01,\n",
       "            7.4115e-01, -3.9256e-01]],\n",
       "\n",
       "         [[ 1.2159e-01, -6.7601e-02, -2.6293e-02,  ..., -9.1494e-03,\n",
       "           -9.8896e-02, -9.5065e-02],\n",
       "          [-4.4361e-01,  6.9136e-01, -4.7706e-02,  ..., -2.3309e-01,\n",
       "            2.2994e-01, -4.2102e-01],\n",
       "          [ 2.4858e-01,  1.2860e-01, -1.7537e+00,  ..., -3.0264e-01,\n",
       "           -7.8342e-02,  2.6685e-01],\n",
       "          [-2.9997e-01,  4.6822e-01, -3.1788e-01,  ...,  3.5175e-01,\n",
       "            2.7898e-01,  1.8905e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-8.5954e-01, -1.4759e-01,  3.4423e-01,  ..., -9.7738e-01,\n",
       "            4.1476e-02, -2.9613e+00],\n",
       "          [ 1.3906e+00,  1.6643e+00, -1.5319e+00,  ..., -1.9960e+00,\n",
       "           -1.1428e+00,  7.7572e+00],\n",
       "          [ 2.3108e+00,  4.8621e-01, -2.0359e+00,  ..., -2.0737e+00,\n",
       "           -2.5124e+00,  8.7697e+00],\n",
       "          [ 1.2236e+00,  2.0161e+00, -2.1268e+00,  ..., -2.6163e+00,\n",
       "            3.8315e-01,  7.9266e+00]],\n",
       "\n",
       "         [[ 3.6654e-01, -6.2164e-02,  4.5589e-01,  ..., -1.3711e-01,\n",
       "           -9.2666e-02, -2.2256e+00],\n",
       "          [-2.1898e+00,  8.7346e-01,  2.9738e+00,  ...,  7.4123e-01,\n",
       "           -1.9773e+00,  7.2935e+00],\n",
       "          [-3.0403e+00,  3.3620e-01,  4.0249e+00,  ..., -9.8823e-01,\n",
       "           -1.5915e+00,  7.3419e+00],\n",
       "          [-1.7781e+00,  3.0064e-01,  3.5579e+00,  ..., -1.1077e+00,\n",
       "           -1.2276e+00,  5.9454e+00]],\n",
       "\n",
       "         [[ 1.3527e-01, -6.4819e-01, -2.1742e-01,  ...,  1.3414e-01,\n",
       "            2.5323e-01, -1.6456e-01],\n",
       "          [-1.0459e+00,  1.9802e+00,  1.2576e+00,  ...,  1.3335e-01,\n",
       "           -7.5849e-01,  1.9973e-02],\n",
       "          [-9.6241e-01,  2.6631e+00,  1.1772e+00,  ..., -9.2805e-02,\n",
       "           -1.4265e-01,  7.1636e-01],\n",
       "          [ 2.0011e+00,  1.4318e+00,  3.8513e-01,  ...,  7.9773e-01,\n",
       "           -1.7876e+00,  7.5930e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.8437e-01,  2.6293e-02, -7.2646e-03,  ...,  1.2316e+00,\n",
       "            4.0667e-02,  1.7827e+00],\n",
       "          [ 1.2403e+00, -2.7193e+00, -2.9260e+00,  ..., -3.5028e+00,\n",
       "           -2.0706e+00, -1.4453e+00],\n",
       "          [ 1.3731e+00, -1.2677e+00,  9.3467e-03,  ..., -3.3472e+00,\n",
       "           -2.4815e-01, -1.8840e+00],\n",
       "          [ 1.7604e+00, -1.4112e+00, -8.8859e-01,  ..., -1.8311e+00,\n",
       "            4.5791e-01, -5.4047e-01]],\n",
       "\n",
       "         [[-3.1699e-01, -1.3868e-01,  2.2315e-01,  ...,  2.6587e-01,\n",
       "           -2.5961e-02,  1.8437e-02],\n",
       "          [-7.1765e-01, -3.3557e-01, -1.5413e-01,  ...,  4.3895e-01,\n",
       "            1.2461e+00,  7.7593e-01],\n",
       "          [ 1.3825e-01, -6.7530e-01, -4.6856e-01,  ...,  9.0584e-01,\n",
       "           -7.7012e-03,  6.2615e-01],\n",
       "          [-1.8277e-01,  9.6367e-01, -1.3012e+00,  ..., -4.9705e-01,\n",
       "            1.4472e+00,  2.2958e-01]],\n",
       "\n",
       "         [[ 3.4151e+00,  2.1488e+00, -2.1320e+00,  ..., -2.8157e+00,\n",
       "           -3.9029e+00, -1.2335e+00],\n",
       "          [-7.0261e-01, -2.2970e+00,  5.4691e+00,  ...,  4.8499e-01,\n",
       "            1.0855e+01, -1.2688e+00],\n",
       "          [-4.0429e+00, -2.0201e+00,  4.2556e+00,  ..., -3.7572e+00,\n",
       "            1.5646e+01,  9.5169e-01],\n",
       "          [-2.5919e+00, -4.0007e+00,  8.0302e+00,  ..., -5.4014e-01,\n",
       "            9.1056e+00, -3.3397e+00]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 1.0092e-02, -3.8597e-02,  1.5103e-02,  ...,  8.1597e-02,\n",
       "            3.4552e-02,  6.4607e-02],\n",
       "          [ 5.7782e-01,  2.9475e-01, -4.1322e-02,  ..., -1.9981e-01,\n",
       "           -3.1371e-01,  7.3702e-03],\n",
       "          [ 2.6446e-01, -1.1596e-01, -1.3475e-01,  ...,  2.4465e-01,\n",
       "            9.3779e-02,  2.1276e-01],\n",
       "          [-4.5847e-01, -1.3694e-01,  4.5275e-01,  ...,  2.1975e-01,\n",
       "           -6.7562e-02,  5.5318e-02]],\n",
       "\n",
       "         [[-6.9855e-02, -1.0825e-02, -1.4234e-01,  ..., -4.1083e-02,\n",
       "            5.0347e-02, -2.6313e-02],\n",
       "          [ 1.9002e-01, -5.0043e-01, -7.1815e-01,  ...,  3.5625e-01,\n",
       "           -7.3163e-01,  1.5081e-01],\n",
       "          [-6.0207e-02,  7.6654e-02, -1.9607e-01,  ...,  2.6973e-01,\n",
       "            8.0200e-02,  2.0202e-01],\n",
       "          [ 8.9006e-02,  2.0114e-01, -2.9845e-01,  ...,  8.3856e-01,\n",
       "            3.0763e-01,  6.8388e-01]],\n",
       "\n",
       "         [[ 5.4650e-02,  9.3255e-02,  9.8528e-02,  ...,  2.1035e-02,\n",
       "           -7.2888e-02,  6.8624e-03],\n",
       "          [-5.6987e-01, -5.7816e-01, -6.0581e-01,  ..., -2.3122e-01,\n",
       "           -1.5149e-01,  8.7276e-02],\n",
       "          [-7.3616e-01,  4.4954e-01, -5.6753e-01,  ...,  1.9245e-01,\n",
       "           -1.2103e-01, -3.5907e-01],\n",
       "          [ 3.7299e-01,  1.6010e+00, -1.2833e-01,  ..., -1.4691e-01,\n",
       "           -4.1989e-01,  8.7407e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.7372e-03,  8.3590e-02, -7.7582e-02,  ...,  3.5149e-02,\n",
       "            4.5994e-02, -1.2726e-01],\n",
       "          [ 7.6514e-01,  6.5536e-01, -4.4284e-01,  ...,  8.7465e-01,\n",
       "           -7.3932e-01,  6.9789e-01],\n",
       "          [ 3.8568e-01,  5.0944e-01,  1.9760e-01,  ...,  1.3398e-01,\n",
       "           -1.5620e-01,  5.8585e-01],\n",
       "          [-8.6510e-01,  6.2967e-01,  4.8496e-01,  ...,  7.1318e-02,\n",
       "           -5.3438e-01,  7.6316e-01]],\n",
       "\n",
       "         [[-1.3346e-01, -5.4564e-02,  1.1251e-01,  ..., -5.6526e-02,\n",
       "            3.7499e-02, -3.0253e-02],\n",
       "          [-4.5346e-01, -1.3068e+00, -6.9632e-01,  ..., -7.2166e-01,\n",
       "           -3.4559e-01,  5.5052e-01],\n",
       "          [-2.1331e-01, -4.6283e-01, -6.9444e-01,  ..., -2.9809e-01,\n",
       "            2.5718e-01,  1.7471e-01],\n",
       "          [-3.3607e-01, -1.9656e-01, -1.1997e+00,  ...,  6.4359e-01,\n",
       "           -5.8129e-01,  8.3982e-01]],\n",
       "\n",
       "         [[-2.2409e-02, -1.7192e-02, -2.5725e-02,  ..., -3.5091e-02,\n",
       "           -1.4392e-03, -1.5489e-02],\n",
       "          [-1.0512e-01, -4.4937e-01, -5.6334e-01,  ...,  1.1462e-01,\n",
       "           -5.0972e-01, -2.0617e-01],\n",
       "          [-1.1367e-01, -1.3732e-01, -6.3006e-01,  ..., -7.9147e-02,\n",
       "           -9.1863e-02, -8.7041e-02],\n",
       "          [-2.6021e-01, -5.4374e-01, -3.8239e-01,  ...,  4.1797e-02,\n",
       "            2.4166e-01, -7.0893e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 2.7813e-02, -2.9738e-01,  2.2939e-01,  ...,  1.7051e+00,\n",
       "           -2.2421e-01, -6.7345e-02],\n",
       "          [ 1.1560e+00,  1.9807e+00,  3.4091e-01,  ..., -4.2132e+00,\n",
       "           -5.4445e-01,  1.0198e+00],\n",
       "          [-7.3837e-02, -4.3244e-01, -8.5305e-01,  ..., -4.9870e+00,\n",
       "           -5.4979e-01,  9.5796e-03],\n",
       "          [ 4.8455e-01,  3.7764e-01, -1.9510e-01,  ..., -3.7633e+00,\n",
       "            2.8818e-01, -9.3021e-01]],\n",
       "\n",
       "         [[ 1.7654e-01,  9.8481e-01, -1.4198e+00,  ..., -1.2411e-01,\n",
       "            2.5963e-01,  9.2172e-01],\n",
       "          [-2.3053e+00, -6.6025e+00,  7.7291e-01,  ..., -4.1412e-01,\n",
       "           -1.8191e-01, -5.3845e-01],\n",
       "          [-2.0771e-01, -6.5940e+00,  1.3623e+00,  ...,  5.1802e-01,\n",
       "           -6.0983e-01, -4.5531e+00],\n",
       "          [-1.2043e+00, -4.1689e+00,  2.3670e-01,  ...,  6.0995e-01,\n",
       "           -1.1979e+00, -2.9129e+00]],\n",
       "\n",
       "         [[-6.8039e-01,  2.5282e-01, -5.3802e-02,  ...,  1.7756e-01,\n",
       "            2.8510e-02, -2.9375e-01],\n",
       "          [ 4.4213e-01,  8.0195e-01, -1.2659e+00,  ..., -1.3908e+00,\n",
       "           -8.1624e-01, -1.7127e+00],\n",
       "          [ 1.0403e+00,  7.7847e-01, -2.6691e-01,  ..., -9.0736e-02,\n",
       "           -4.2508e-01, -7.1313e-01],\n",
       "          [ 2.1294e+00, -7.2655e-01, -8.4549e-01,  ...,  3.8757e-01,\n",
       "            1.3703e+00, -1.0432e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.7233e-02,  1.1712e-01,  1.5510e-01,  ..., -1.0130e-01,\n",
       "            1.6923e-02,  1.5087e-01],\n",
       "          [ 1.2120e+00, -4.9320e-01, -1.4343e+00,  ...,  1.4606e+00,\n",
       "           -6.0549e-01,  9.7077e-02],\n",
       "          [ 2.3070e-01,  2.8884e-01, -3.5044e-02,  ...,  1.5829e+00,\n",
       "            4.2646e-01, -1.5025e-02],\n",
       "          [ 7.1532e-01, -4.2930e-01, -3.9113e-01,  ...,  1.3689e+00,\n",
       "           -8.6316e-01,  5.6682e-01]],\n",
       "\n",
       "         [[-3.0046e+00,  3.8665e-01,  1.1992e-03,  ..., -4.6510e-01,\n",
       "           -3.3736e-01,  1.2333e+00],\n",
       "          [ 5.0714e+00, -3.9464e-01, -1.6977e+00,  ..., -6.2442e-03,\n",
       "            1.6519e+00, -7.3742e-01],\n",
       "          [ 5.8935e+00, -4.6477e-01, -1.9044e+00,  ..., -3.4121e-01,\n",
       "            6.6325e-01, -4.8435e-02],\n",
       "          [ 6.5820e+00,  2.4343e-01, -1.1181e+00,  ..., -1.0346e+00,\n",
       "           -3.7290e-01, -6.4632e-01]],\n",
       "\n",
       "         [[-2.5226e-02, -2.3976e-01,  2.3566e-02,  ..., -1.7505e-01,\n",
       "            3.3510e-01,  9.8084e-02],\n",
       "          [ 9.5364e-01, -2.6201e+00,  5.9773e-01,  ..., -1.7090e+00,\n",
       "            6.0144e-01, -2.4447e-01],\n",
       "          [ 3.0071e-01, -3.0612e+00,  1.2574e+00,  ...,  1.7366e-01,\n",
       "            4.9911e-01, -7.0210e-01],\n",
       "          [ 7.9747e-02, -2.1842e+00,  4.6621e-02,  ...,  7.9092e-01,\n",
       "           -5.6585e-01, -4.4715e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-2.6984e-02, -2.0164e-02,  5.0374e-03,  ..., -6.8925e-03,\n",
       "           -3.4602e-02,  3.5709e-01],\n",
       "          [ 3.5157e+00,  8.3853e-02,  8.6206e-01,  ...,  2.4324e-01,\n",
       "            8.4686e-01, -6.8514e-01],\n",
       "          [ 2.0225e+00, -6.9720e-01, -1.7987e-01,  ...,  3.0111e-01,\n",
       "            8.3233e-01, -1.3597e+00],\n",
       "          [ 8.4030e-01,  1.0043e+00,  3.8162e-01,  ..., -3.9461e-01,\n",
       "            5.7322e-01, -1.2207e+00]],\n",
       "\n",
       "         [[ 6.4696e-03, -1.0245e-02,  2.2730e-02,  ..., -1.9925e-02,\n",
       "            2.3835e-02,  7.9483e-03],\n",
       "          [ 1.1263e+00,  5.5300e-02,  3.0088e-01,  ..., -9.0048e-01,\n",
       "            9.8814e-01, -1.3165e+00],\n",
       "          [ 1.3333e+00, -7.7070e-01, -4.7249e-01,  ..., -3.2184e-01,\n",
       "            1.9386e+00,  6.4203e-02],\n",
       "          [ 8.0709e-01, -5.2763e-01,  6.3489e-01,  ..., -9.1817e-01,\n",
       "            1.2946e+00,  1.4282e-02]],\n",
       "\n",
       "         [[-5.7165e-02,  3.0677e-03, -3.8122e-02,  ..., -2.9978e-02,\n",
       "            9.4247e-03, -8.2960e-02],\n",
       "          [-1.1542e+00, -1.2845e+00,  1.9795e-01,  ..., -7.9208e-01,\n",
       "            6.5039e-02, -1.2112e+00],\n",
       "          [-1.0968e-01, -1.1066e+00,  1.8408e+00,  ..., -8.1574e-01,\n",
       "            1.6497e+00, -2.4946e-01],\n",
       "          [-4.1045e-01, -4.5911e-01,  9.9842e-01,  ..., -8.0518e-01,\n",
       "            7.2723e-01,  5.1027e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.3787e-01, -1.9701e-01, -5.4383e-02,  ..., -4.7772e-01,\n",
       "            2.0819e-01,  9.0011e-02],\n",
       "          [ 4.6317e-01, -1.2435e+00, -2.4910e-01,  ...,  3.4236e-01,\n",
       "           -3.5276e-01, -1.3201e-01],\n",
       "          [ 1.8349e-01, -2.3081e+00, -1.1747e-01,  ...,  2.1739e+00,\n",
       "            1.3752e+00,  3.4934e-02],\n",
       "          [ 1.1651e+00, -6.9961e-01,  1.4149e+00,  ...,  2.5042e+00,\n",
       "           -7.6784e-01, -4.1217e-01]],\n",
       "\n",
       "         [[-8.4285e-02, -1.3500e-01, -5.6382e-02,  ..., -1.8585e-01,\n",
       "           -1.3389e-01,  1.2310e-01],\n",
       "          [-8.3389e-01,  8.2294e-02, -6.0660e-01,  ...,  3.6324e-01,\n",
       "            1.3901e-01,  8.0781e-01],\n",
       "          [-7.9436e-01, -4.5892e-01, -1.5258e-02,  ...,  3.4279e-01,\n",
       "           -9.6421e-01,  1.2833e+00],\n",
       "          [-2.8685e-01, -5.3533e-01, -1.6538e+00,  ...,  1.0482e+00,\n",
       "           -6.2765e-02, -8.9860e-02]],\n",
       "\n",
       "         [[-3.3710e-02, -3.3108e-02,  9.0004e-02,  ...,  7.0208e-02,\n",
       "           -2.2221e-02,  3.2434e-02],\n",
       "          [ 2.3834e-01, -3.3439e-01, -5.5056e-01,  ..., -5.4657e-01,\n",
       "           -3.8251e-01, -1.1597e-01],\n",
       "          [ 5.3751e-01, -9.2909e-01, -1.2154e+00,  ..., -5.3453e-01,\n",
       "            2.4458e-01, -2.8460e-01],\n",
       "          [-8.8593e-02,  9.6412e-01, -2.0194e-01,  ..., -3.7182e-01,\n",
       "           -8.8493e-02,  6.1532e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-3.4302e-01,  8.5662e-01, -1.5844e-01,  ...,  1.1255e+00,\n",
       "           -1.8499e-01,  1.4738e-01],\n",
       "          [-9.8221e-01, -6.0974e+00,  2.3096e-01,  ..., -2.8724e+00,\n",
       "            1.3048e+00,  1.7041e+00],\n",
       "          [-2.1738e+00, -5.0046e+00,  3.1584e-01,  ..., -3.6094e+00,\n",
       "            8.3111e-01,  2.5185e+00],\n",
       "          [-5.1108e-01, -4.9796e+00, -1.0101e+00,  ..., -3.9293e+00,\n",
       "            8.3226e-01,  2.7076e+00]],\n",
       "\n",
       "         [[ 4.9585e-02,  8.5003e-01, -6.2524e-01,  ..., -3.1143e-02,\n",
       "            2.9301e-01,  2.9644e-03],\n",
       "          [ 1.4902e+00, -1.3111e+00,  1.2934e+00,  ...,  7.8393e-01,\n",
       "           -6.8161e-01,  8.6348e-01],\n",
       "          [ 6.6224e-01, -3.9756e-01,  3.1617e-01,  ...,  2.1208e+00,\n",
       "           -9.8085e-01,  1.2775e+00],\n",
       "          [-1.6071e-01,  8.6698e-01,  1.0606e+00,  ...,  2.0383e+00,\n",
       "           -1.9785e+00,  3.6504e-01]],\n",
       "\n",
       "         [[-3.0184e-01,  1.3559e-01, -9.7893e-01,  ..., -3.5595e-01,\n",
       "           -5.2620e-02, -1.2950e-01],\n",
       "          [ 9.2852e-01, -7.7335e-01,  4.4539e+00,  ...,  9.1257e-01,\n",
       "            3.8662e-01,  1.0528e+00],\n",
       "          [-8.1327e-02, -2.5160e-01,  2.9013e+00,  ...,  8.4982e-01,\n",
       "            8.0700e-02,  1.0215e+00],\n",
       "          [ 2.6994e-02,  7.1141e-02,  2.8590e+00,  ...,  1.2593e+00,\n",
       "            7.1855e-01,  5.7011e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.7086e-01,  7.1807e-02, -5.5858e-02,  ..., -5.2340e-02,\n",
       "            2.3087e-01,  2.6214e-02],\n",
       "          [-2.3071e+00, -3.7160e-02,  3.7996e-03,  ..., -9.0778e-01,\n",
       "           -8.6965e-01,  2.6638e-01],\n",
       "          [-2.0763e+00, -1.3780e+00,  1.8536e+00,  ..., -1.7385e+00,\n",
       "            5.4942e-01,  5.6473e-01],\n",
       "          [-1.6781e+00, -3.0081e-01,  6.3500e-01,  ..., -1.4023e+00,\n",
       "            6.9758e-01,  9.8113e-01]],\n",
       "\n",
       "         [[ 2.1346e-01,  6.2942e-02,  3.1805e-01,  ...,  4.2218e-01,\n",
       "            2.2139e-02,  2.2548e-01],\n",
       "          [ 1.3344e+00,  2.6482e-01,  1.9796e-01,  ..., -1.3528e+00,\n",
       "            2.8633e-01, -5.4602e-01],\n",
       "          [ 1.6408e+00,  8.9649e-01,  1.7704e+00,  ..., -1.1865e+00,\n",
       "            7.1882e-03, -1.9584e-01],\n",
       "          [ 1.3553e+00,  1.1259e+00,  2.1333e+00,  ..., -1.1618e+00,\n",
       "           -1.0152e+00,  9.2576e-02]],\n",
       "\n",
       "         [[-3.0241e+00,  5.3479e-01,  5.5213e-01,  ..., -9.3664e-01,\n",
       "            3.3797e-01,  1.7848e-01],\n",
       "          [ 7.5235e+00, -9.7337e-01, -3.3501e+00,  ...,  1.1598e+00,\n",
       "           -3.7886e-02, -1.8685e+00],\n",
       "          [ 8.6526e+00, -6.7875e-01, -2.7323e+00,  ...,  1.3511e+00,\n",
       "           -3.6760e-01, -3.3839e-01],\n",
       "          [ 7.1121e+00, -8.7711e-01, -3.7270e+00,  ...,  1.7786e+00,\n",
       "           -6.4230e-01, -1.1938e+00]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 4.0038e-02, -4.6520e-02,  1.5460e-02,  ..., -7.6390e-02,\n",
       "            3.1671e-03, -9.3498e-02],\n",
       "          [-3.1402e-01,  5.7923e-01, -8.8708e-01,  ..., -8.7879e-03,\n",
       "           -4.5486e-01,  4.2748e-01],\n",
       "          [-9.6833e-01,  5.3658e-01, -6.7830e-01,  ..., -8.5006e-01,\n",
       "           -4.9921e-01, -1.1073e-01],\n",
       "          [-3.2261e-01, -4.1914e-01, -8.0090e-02,  ...,  1.9661e-01,\n",
       "           -2.4236e-01,  3.0083e-01]],\n",
       "\n",
       "         [[ 7.0871e-02,  1.3237e-02, -2.4383e-02,  ..., -3.4632e-02,\n",
       "            2.3343e-02, -9.1591e-03],\n",
       "          [-1.0497e-01,  3.4039e-01, -5.4393e-01,  ...,  1.8646e+00,\n",
       "            3.9368e-01,  1.3653e-03],\n",
       "          [-6.2479e-01,  2.7008e-01, -1.3427e+00,  ...,  2.3230e-01,\n",
       "           -7.1329e-02, -1.1569e+00],\n",
       "          [-2.9498e-01, -2.6461e-01, -1.1951e-01,  ...,  4.6111e-01,\n",
       "            1.7252e-01, -1.4420e+00]],\n",
       "\n",
       "         [[ 6.7562e-02,  9.2476e-03,  5.6079e-03,  ...,  1.6537e-02,\n",
       "           -7.0947e-02, -5.0142e-02],\n",
       "          [ 1.0928e+00, -4.9725e-01,  2.4872e-01,  ..., -5.3681e-01,\n",
       "           -8.9556e-01,  2.4767e+00],\n",
       "          [-5.7101e-01, -6.4822e-01,  3.6244e-01,  ..., -3.8311e-01,\n",
       "            2.1265e-01,  1.0888e+00],\n",
       "          [-8.3365e-01, -1.6450e-01,  5.7330e-01,  ..., -3.0677e-01,\n",
       "            1.4922e+00,  5.9910e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.9117e-03,  3.5666e-02,  2.5208e-02,  ..., -8.5449e-02,\n",
       "           -2.7288e-02,  2.8385e-02],\n",
       "          [-6.4267e-01, -3.6399e-01,  8.5654e-01,  ...,  9.5849e-01,\n",
       "           -9.4165e-01, -1.0743e+00],\n",
       "          [ 4.5890e-02, -3.3962e-01,  6.1837e-02,  ...,  9.2879e-01,\n",
       "           -2.2462e+00,  1.1331e-01],\n",
       "          [-1.9844e+00, -5.5259e-01, -4.1474e-01,  ...,  3.8307e-01,\n",
       "           -7.6431e-01,  4.0974e-01]],\n",
       "\n",
       "         [[ 4.6145e-02, -1.1842e-02,  1.6848e-02,  ...,  3.3342e-02,\n",
       "           -1.6606e-02,  6.8649e-03],\n",
       "          [-3.2603e-01,  2.1603e-02, -9.1946e-01,  ...,  7.3563e-01,\n",
       "            9.8704e-02,  3.4009e-01],\n",
       "          [-6.6312e-01,  7.7206e-01, -2.7404e-01,  ...,  1.4155e+00,\n",
       "           -1.5234e+00, -1.7455e-01],\n",
       "          [-1.0075e+00,  1.5529e+00, -6.3020e-01,  ...,  6.1944e-01,\n",
       "            4.2378e-01, -5.4371e-01]],\n",
       "\n",
       "         [[ 6.4984e-02, -1.8694e-01, -7.6296e-02,  ..., -3.2548e-02,\n",
       "            2.0488e-01, -6.0437e-02],\n",
       "          [-5.6906e-01, -5.5347e-01, -2.5299e-01,  ...,  6.4095e-01,\n",
       "            3.0172e-01,  4.7557e-01],\n",
       "          [-3.9948e-01,  5.9364e-01, -1.3460e-01,  ...,  2.8066e-01,\n",
       "            2.8303e-01,  1.0703e+00],\n",
       "          [-2.9285e-01,  9.2804e-01,  7.0381e-02,  ...,  2.8434e-02,\n",
       "           -2.0948e-01,  1.2836e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.0588, -0.2618, -0.1146,  ...,  0.6002,  0.7217, -0.3155],\n",
       "          [-3.3234, -0.8892,  2.3427,  ..., -0.4392, -4.8010, -0.0623],\n",
       "          [-3.7055, -0.8078,  2.0409,  ..., -0.4223, -3.5455, -0.4040],\n",
       "          [-2.9610, -0.2348,  0.4844,  ..., -1.9706, -4.6075, -0.0792]],\n",
       "\n",
       "         [[-0.1562, -0.0665,  0.1487,  ..., -0.0359, -0.8873, -0.1945],\n",
       "          [-1.5316,  0.5248, -0.3032,  ...,  0.0957, -0.9650,  1.1402],\n",
       "          [-1.7357,  0.5567, -0.2924,  ...,  1.7802, -0.6381, -0.4213],\n",
       "          [-1.6753,  1.2857, -0.1199,  ...,  0.5660, -0.6302,  0.9016]],\n",
       "\n",
       "         [[ 0.1900,  0.2841,  1.1315,  ..., -0.4526,  0.4354, -0.5158],\n",
       "          [ 0.1528, -1.9978, -0.3708,  ...,  0.3347, -2.7449,  0.3737],\n",
       "          [-0.6951, -2.0696, -0.7766,  ...,  0.4536, -4.2618, -0.1142],\n",
       "          [-0.1676, -1.4145,  0.2474,  ...,  0.2484, -3.0327,  1.7436]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1398,  0.0641, -0.2197,  ..., -0.0077,  0.1507,  0.0279],\n",
       "          [-2.3230, -0.8592, -0.3975,  ...,  0.3576,  0.7798, -0.8048],\n",
       "          [-0.0645, -0.8703,  0.4008,  ...,  1.0482,  0.0758,  0.3258],\n",
       "          [-2.0481, -0.1481, -0.4346,  ...,  0.7634, -0.2254, -1.2330]],\n",
       "\n",
       "         [[-0.3630, -2.1828,  0.1336,  ..., -0.0918, -0.0443,  0.9114],\n",
       "          [-1.0437,  3.1372,  2.3359,  ..., -0.1186,  0.0622,  0.5354],\n",
       "          [-0.0879,  5.9737,  1.1913,  ..., -0.9283, -0.5580, -0.5701],\n",
       "          [ 0.0738,  3.3133,  0.8634,  ..., -0.2604, -0.0895,  0.5025]],\n",
       "\n",
       "         [[ 0.3818,  0.0673, -0.1448,  ...,  0.6512,  0.1291,  0.2677],\n",
       "          [-0.1103, -1.2616, -1.9140,  ...,  0.2368,  0.3264,  0.3480],\n",
       "          [-1.8964, -0.5648,  0.2609,  ..., -0.2958, -1.1712,  0.8259],\n",
       "          [-1.4328, -0.4522,  1.1597,  ...,  0.0408,  0.5294,  1.0270]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>), tensor([[[[-3.9849e-02,  5.5808e-02, -5.6233e-02,  ..., -2.5045e-02,\n",
       "           -1.0674e-03,  2.7187e-02],\n",
       "          [-1.1501e-02,  1.3780e+00,  4.3291e-01,  ..., -3.9653e-02,\n",
       "           -6.9986e-01, -3.1786e-01],\n",
       "          [ 6.1239e-01,  1.2644e+00,  1.6732e+00,  ..., -2.5910e-02,\n",
       "           -2.0226e+00, -9.6210e-01],\n",
       "          [ 3.6837e-01,  1.1231e+00,  3.3028e-01,  ..., -2.5728e-01,\n",
       "           -8.1186e-01, -4.6699e-01]],\n",
       "\n",
       "         [[ 7.2569e-03, -2.0401e-02,  2.7171e-02,  ...,  2.0418e-02,\n",
       "           -5.9097e-02,  2.3373e-02],\n",
       "          [ 6.1565e-02, -1.8947e-01, -4.7616e-02,  ...,  2.0409e-02,\n",
       "           -3.2605e-01,  6.8020e-01],\n",
       "          [ 6.2378e-01,  7.2997e-01, -4.3990e-01,  ..., -5.0196e-01,\n",
       "           -5.0919e-01,  5.7007e-01],\n",
       "          [ 4.9256e-01, -3.4601e-01, -4.9427e-02,  ...,  1.9771e+00,\n",
       "           -6.3772e-01,  5.8095e-01]],\n",
       "\n",
       "         [[ 4.8845e-02, -3.0869e-02,  4.7578e-02,  ...,  3.4715e-02,\n",
       "           -1.9837e-02,  4.5811e-03],\n",
       "          [ 1.8204e-01, -1.2011e-01, -1.8489e+00,  ..., -2.8083e-01,\n",
       "           -4.5248e-01,  1.9522e-01],\n",
       "          [-1.8280e-01, -1.3917e+00,  2.7230e-01,  ...,  8.6140e-01,\n",
       "            7.0586e-01,  1.9181e+00],\n",
       "          [-1.2039e+00,  7.3012e-01,  1.3145e-01,  ...,  8.8091e-01,\n",
       "           -5.3773e-01, -1.1593e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.8527e-01,  9.5715e-02,  5.6666e-02,  ...,  4.7971e-02,\n",
       "            3.8836e-02, -1.2407e-01],\n",
       "          [ 3.2954e-01, -1.0895e+00, -4.5125e-01,  ...,  3.1932e-01,\n",
       "            8.9423e-01, -8.8257e-01],\n",
       "          [ 3.7132e-01, -6.3280e-01, -2.5238e-02,  ...,  1.3771e+00,\n",
       "           -3.8321e-01, -1.2792e+00],\n",
       "          [-4.9862e-01, -1.4251e+00,  2.6062e-01,  ...,  1.0351e+00,\n",
       "            3.2344e-01,  3.0645e-01]],\n",
       "\n",
       "         [[-5.8415e-01, -4.6983e-04,  4.4714e-02,  ..., -2.3126e-02,\n",
       "            1.8337e-02, -1.5615e-02],\n",
       "          [-1.6383e+00, -1.2081e-01, -6.9330e-01,  ...,  1.1016e+00,\n",
       "            1.0749e+00,  3.4465e-01],\n",
       "          [-2.7475e+00,  3.1973e-01, -1.1697e+00,  ...,  1.0573e+00,\n",
       "            1.4021e+00,  5.4870e-01],\n",
       "          [-1.2323e+00,  1.4951e-01, -1.9396e+00,  ...,  5.3772e-01,\n",
       "           -1.7202e+00, -5.9633e-01]],\n",
       "\n",
       "         [[ 7.7953e-03,  9.2087e-02, -4.0258e-02,  ...,  6.5219e-02,\n",
       "            3.1357e-02, -4.8461e-02],\n",
       "          [-1.0463e+00,  7.7840e-01, -1.2806e+00,  ..., -5.0540e-01,\n",
       "           -2.1162e+00,  9.7017e-02],\n",
       "          [-1.8473e+00,  8.2527e-01, -3.0206e-01,  ..., -6.1512e-01,\n",
       "           -1.0327e+00, -6.1386e-01],\n",
       "          [-2.6192e-01,  3.9993e-02, -3.1222e-01,  ...,  7.0793e-01,\n",
       "           -2.0886e+00, -8.8737e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-0.0304, -2.3308,  0.1726,  ..., -0.2217, -0.2086,  0.0715],\n",
       "          [-0.4927,  5.1493,  1.3386,  ...,  0.2459, -0.7042, -0.6444],\n",
       "          [-0.0607,  5.1882,  1.9929,  ..., -0.3150,  0.1796, -0.0352],\n",
       "          [ 0.0732,  5.3236,  0.6340,  ...,  0.2698,  0.1409,  0.8464]],\n",
       "\n",
       "         [[-0.8126,  0.2211,  0.4645,  ..., -0.5159,  1.0718,  1.1199],\n",
       "          [-0.6428, -0.0634,  2.4847,  ...,  1.7112,  2.0623,  0.3937],\n",
       "          [ 1.2810,  1.0915,  0.2288,  ...,  1.7819,  1.6649, -0.6532],\n",
       "          [-0.2482,  0.6107,  0.3466,  ..., -0.1595,  1.5192,  0.0925]],\n",
       "\n",
       "         [[-0.8464,  0.4777,  0.0212,  ...,  0.4965, -0.2482,  1.1645],\n",
       "          [ 1.0941, -1.8319,  1.8245,  ...,  0.4363,  0.1803, -0.2293],\n",
       "          [ 1.1356, -0.9983, -0.0147,  ...,  1.0020,  0.7875,  0.3698],\n",
       "          [ 1.9471,  0.0566,  0.0405,  ...,  1.0989, -0.7768,  0.2699]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.3137, -0.1465,  0.1402,  ...,  0.1828,  1.7306, -2.8564],\n",
       "          [-0.0889, -0.8922, -0.4220,  ..., -0.5580, -6.1711,  6.7055],\n",
       "          [ 0.3122, -0.9844, -0.0790,  ..., -1.3162, -5.7916,  7.0884],\n",
       "          [-0.0766, -1.6332, -0.2011,  ..., -0.0957, -3.9167,  5.1490]],\n",
       "\n",
       "         [[ 0.1733,  0.3767,  0.2181,  ..., -0.2210,  0.0372, -0.1505],\n",
       "          [-0.6370, -0.2938,  0.6357,  ...,  1.4049,  0.3261, -2.1111],\n",
       "          [-0.8776, -0.0954,  0.4646,  ...,  1.5699,  0.6666, -2.1886],\n",
       "          [-1.0744, -0.0719, -0.1091,  ...,  1.7218,  1.6005, -1.9641]],\n",
       "\n",
       "         [[ 0.3681,  0.1235,  0.6221,  ...,  0.5272,  0.5711, -0.3273],\n",
       "          [ 0.5225, -0.8063, -0.2709,  ..., -2.6602, -4.5037,  1.2450],\n",
       "          [-1.0639, -1.0463, -2.6577,  ..., -2.3066, -4.5093,  1.6932],\n",
       "          [-0.0287, -1.5930, -1.3594,  ..., -1.0944, -3.4261,  0.3396]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>), tensor([[[[ 0.0545, -0.0055, -0.0159,  ...,  0.1347, -0.0492, -0.0255],\n",
       "          [-1.3729, -1.2261, -0.4391,  ...,  0.2989,  0.9716,  1.1252],\n",
       "          [-1.1722, -0.3700, -1.7924,  ...,  1.0633, -0.0433,  0.8889],\n",
       "          [-1.6241,  0.4562,  0.4890,  ..., -0.1210,  0.8871, -0.1568]],\n",
       "\n",
       "         [[ 0.0056,  0.0446,  0.0525,  ..., -0.0125, -0.0053,  0.0172],\n",
       "          [ 0.4374, -0.9622,  0.2597,  ..., -0.5054,  0.9170,  0.3522],\n",
       "          [-0.7719, -0.1153,  1.4847,  ...,  1.1166,  0.7985,  0.5398],\n",
       "          [ 0.0144,  1.2302,  1.8236,  ..., -0.1142,  0.3004, -0.7279]],\n",
       "\n",
       "         [[ 0.0512, -0.0434,  0.0666,  ...,  0.0437, -0.0677, -0.0705],\n",
       "          [-0.1644,  0.2565,  0.7966,  ..., -0.9864,  0.5151,  0.3353],\n",
       "          [-0.7832, -0.7402, -0.7030,  ..., -0.2299,  1.1811,  0.0890],\n",
       "          [-0.4143, -1.1424,  0.5212,  ..., -0.4642,  0.6755, -0.3627]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0929, -0.0464,  0.0310,  ..., -0.0941,  0.0378,  0.0102],\n",
       "          [-0.4399,  0.3174,  2.0826,  ..., -1.2379,  1.9694, -0.2540],\n",
       "          [-0.3413,  1.3039,  1.3967,  ..., -0.6271,  2.5072, -1.3013],\n",
       "          [-0.4295,  0.5826,  0.2012,  ..., -0.7119,  1.1825, -1.0583]],\n",
       "\n",
       "         [[ 0.1667, -0.0947,  0.1190,  ...,  0.0664,  0.0246, -0.1234],\n",
       "          [-0.2828, -1.3959, -1.2321,  ...,  0.7993,  2.4947,  1.2507],\n",
       "          [-0.8732, -0.3519, -1.6929,  ...,  0.9131,  1.1351,  1.0339],\n",
       "          [-1.3183, -0.7768, -1.5077,  ..., -0.0716, -1.6006,  0.3218]],\n",
       "\n",
       "         [[ 0.2160, -0.0353, -0.0436,  ...,  0.0388,  0.0401,  0.0198],\n",
       "          [ 0.0941, -0.3919,  0.4767,  ..., -0.9538,  1.3043,  0.4941],\n",
       "          [-0.2053, -1.3497,  1.2805,  ...,  0.2111, -1.5031,  0.6873],\n",
       "          [-0.9913, -0.0297,  1.3556,  ...,  0.2196,  0.6218, -0.3870]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>)), (tensor([[[[ 4.7919e-02, -2.4689e-01, -4.4802e-01,  ...,  3.0240e-01,\n",
       "            3.2860e-01,  3.7058e-01],\n",
       "          [ 1.5159e+00,  1.6773e+00, -3.2377e-01,  ...,  2.2449e+00,\n",
       "           -1.1470e+00,  1.1106e-01],\n",
       "          [ 1.2364e+00, -4.2432e-01,  3.8993e-01,  ...,  9.7888e-01,\n",
       "           -1.6784e+00, -2.3422e-01],\n",
       "          [ 2.3633e-01, -1.4124e+00, -9.2017e-01,  ...,  8.6665e-01,\n",
       "           -6.4067e-01,  1.1016e+00]],\n",
       "\n",
       "         [[-2.8578e-01,  1.7551e-01,  1.2057e-01,  ...,  3.9383e-02,\n",
       "           -1.1355e+00, -1.2655e-01],\n",
       "          [ 3.1154e-01,  1.8124e+00,  4.0465e-01,  ...,  1.0549e+00,\n",
       "           -4.4791e-01,  2.5763e+00],\n",
       "          [ 2.0353e+00,  8.7505e-01, -2.6794e-02,  ...,  3.0205e+00,\n",
       "           -3.1523e-01, -2.2014e-01],\n",
       "          [-2.9918e-01,  3.9576e-01,  1.0553e+00,  ...,  4.6769e-01,\n",
       "           -1.3324e+00, -1.7683e-01]],\n",
       "\n",
       "         [[-1.2388e+00, -9.5323e-02,  5.6034e-01,  ..., -6.5487e-01,\n",
       "            4.5281e-01, -2.7915e-01],\n",
       "          [ 9.7236e-01,  4.7859e-01, -1.7061e-03,  ...,  1.6487e+00,\n",
       "           -6.0558e-01,  8.3555e-01],\n",
       "          [ 1.9840e+00,  1.0034e+00, -1.0990e+00,  ...,  4.4252e-01,\n",
       "           -1.8588e+00,  7.3476e-01],\n",
       "          [ 1.5789e+00,  2.2652e+00, -5.1618e-01,  ..., -3.5103e-01,\n",
       "           -3.1035e-01,  1.0217e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.8210e-01, -8.9509e-01, -3.8749e-01,  ..., -1.0477e+00,\n",
       "           -4.2503e-01,  4.8031e-01],\n",
       "          [ 4.7705e-01,  9.8366e-01, -1.4141e+00,  ..., -1.5527e+00,\n",
       "            8.9130e-01, -3.7348e-01],\n",
       "          [ 4.5510e-01,  1.9300e+00, -1.2675e+00,  ..., -2.0997e+00,\n",
       "           -9.5460e-01, -2.9255e-02],\n",
       "          [ 6.6729e-01,  9.7789e-01, -2.6631e+00,  ..., -1.7355e+00,\n",
       "           -6.6650e-01, -5.8687e-01]],\n",
       "\n",
       "         [[-9.1002e-01,  2.5506e+00,  3.0146e-01,  ...,  3.6401e-01,\n",
       "            1.9539e+00, -5.3125e-01],\n",
       "          [ 5.2163e-01, -2.8496e+00,  4.9212e-01,  ...,  1.0314e+00,\n",
       "           -5.6328e+00,  1.7405e+00],\n",
       "          [ 1.7440e+00, -3.2127e+00,  2.6081e-01,  ...,  5.7413e-01,\n",
       "           -4.9809e+00,  9.1803e-01],\n",
       "          [-4.0521e-01, -3.1543e+00,  1.2410e+00,  ..., -2.4496e-01,\n",
       "           -3.6984e+00,  1.5694e+00]],\n",
       "\n",
       "         [[-2.0206e+00, -3.4801e-01, -1.1077e+00,  ..., -3.8167e-01,\n",
       "            5.0069e-02,  2.5441e-01],\n",
       "          [ 3.6624e+00,  1.5474e-01,  9.2059e-01,  ...,  1.7451e-01,\n",
       "            1.1541e-01, -4.6847e-01],\n",
       "          [ 4.1533e+00, -8.1282e-01,  4.2761e-01,  ..., -1.1157e+00,\n",
       "            1.1281e-01, -1.5886e-01],\n",
       "          [ 3.1807e+00, -9.1308e-01,  4.8433e-01,  ..., -1.8245e-01,\n",
       "           -9.7361e-01, -3.0537e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-3.0952e-02, -7.4426e-02,  1.1553e-02,  ...,  1.1968e-01,\n",
       "           -3.1370e-02,  2.3437e-02],\n",
       "          [ 6.5415e-01,  1.1170e+00, -8.7400e-01,  ...,  8.6474e-01,\n",
       "           -4.4421e-01,  8.0979e-01],\n",
       "          [-1.0309e-01,  1.2140e+00, -1.2481e+00,  ...,  6.9520e-01,\n",
       "           -3.8016e-01,  3.1152e-01],\n",
       "          [-1.7954e-01, -2.8484e-01, -1.6651e+00,  ...,  2.7071e-01,\n",
       "            6.5699e-01,  5.1581e-01]],\n",
       "\n",
       "         [[ 9.9501e-03,  1.2824e-02, -3.8781e-02,  ...,  2.7309e-02,\n",
       "            1.8148e-02,  4.7424e-02],\n",
       "          [-7.0114e-01, -6.4954e-01, -9.5652e-01,  ...,  1.0288e+00,\n",
       "           -9.4382e-01,  1.6587e-01],\n",
       "          [-1.4298e-01,  1.8599e+00,  3.5326e-01,  ...,  1.8403e-01,\n",
       "           -3.3220e-01,  1.6024e-01],\n",
       "          [-4.8602e-01,  4.8138e-01, -1.0618e+00,  ...,  1.5125e+00,\n",
       "            1.2744e+00,  2.0078e-01]],\n",
       "\n",
       "         [[ 2.3149e-02,  3.9486e-02, -8.1933e-02,  ..., -1.1210e-03,\n",
       "           -6.2881e-03,  5.4220e-03],\n",
       "          [-1.1653e+00,  5.6182e-02,  8.4672e-01,  ..., -1.7341e-01,\n",
       "            4.3908e-01, -6.5345e-01],\n",
       "          [-5.3207e-01,  1.0027e+00,  7.1555e-02,  ..., -5.8770e-01,\n",
       "            2.3926e-01, -9.8281e-01],\n",
       "          [ 1.0512e+00,  6.2948e-02, -1.5156e+00,  ..., -5.7342e-01,\n",
       "            2.0089e-01, -8.9955e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.9802e-02,  3.9874e-02,  6.7836e-03,  ..., -3.2768e-03,\n",
       "           -3.6002e-02,  1.5063e-02],\n",
       "          [ 9.3132e-01,  8.0294e-01, -3.0615e-01,  ...,  3.1016e-01,\n",
       "           -2.2154e+00, -2.8667e-01],\n",
       "          [-2.7846e+00,  3.2104e+00,  2.9819e-01,  ...,  7.6209e-01,\n",
       "            1.6278e-01,  2.2083e+00],\n",
       "          [-1.2181e+00, -1.5249e+00,  3.5014e-01,  ...,  1.7220e+00,\n",
       "            4.8842e-01, -1.3106e+00]],\n",
       "\n",
       "         [[-6.1034e-02, -3.9366e-02,  2.7226e-02,  ...,  2.8291e-02,\n",
       "           -5.8517e-02, -1.0155e-01],\n",
       "          [ 6.2353e-01, -4.2391e-01,  6.7199e-01,  ...,  4.4652e-01,\n",
       "           -2.0940e-02, -7.2422e-01],\n",
       "          [ 1.7678e+00, -5.0757e-01, -3.7490e-02,  ..., -9.8968e-02,\n",
       "            8.0979e-01, -6.0455e-01],\n",
       "          [ 8.6174e-01, -5.5698e-01, -9.7872e-01,  ...,  6.0877e-01,\n",
       "            6.7499e-02,  4.2452e-01]],\n",
       "\n",
       "         [[-1.1457e-03,  3.8870e-02, -5.3933e-02,  ..., -4.0716e-03,\n",
       "            9.5693e-03,  1.0241e-02],\n",
       "          [ 6.9607e-01, -5.9638e-01, -9.5722e-01,  ..., -2.3187e-01,\n",
       "            2.9824e-01, -4.8884e-01],\n",
       "          [ 2.8344e-01,  2.2406e-01, -6.6804e-01,  ...,  3.0732e-01,\n",
       "           -2.5341e-01,  2.8978e-01],\n",
       "          [-1.4153e+00, -1.2865e-01, -7.5363e-01,  ...,  9.1823e-01,\n",
       "            1.8409e+00,  9.9141e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-0.5065,  0.4840, -0.8440,  ..., -1.0246, -1.3217,  0.2005],\n",
       "          [ 0.8755, -0.2825, -0.4260,  ...,  1.1609,  1.6701, -1.3837],\n",
       "          [ 1.2156,  0.1344,  0.1099,  ...,  1.9960,  1.3201, -2.1652],\n",
       "          [-0.9811,  0.0516, -1.7722,  ...,  1.4083, -0.2591, -1.5722]],\n",
       "\n",
       "         [[ 0.8482, -2.0621,  0.1634,  ...,  0.2289, -2.4648, -0.4339],\n",
       "          [ 0.9135,  2.1652,  1.0211,  ..., -0.2493,  1.5895, -0.4220],\n",
       "          [ 0.5108,  2.7647, -1.5154,  ..., -1.3396,  4.0151, -0.3852],\n",
       "          [ 0.3503,  1.7707,  0.1698,  ...,  0.5410,  0.7971, -1.0302]],\n",
       "\n",
       "         [[ 1.0028,  0.3803, -0.1885,  ..., -0.8128, -1.3883, -0.3525],\n",
       "          [-1.0399, -0.8577, -1.6560,  ...,  0.9870, -0.0754,  0.1111],\n",
       "          [-0.6555, -1.7872, -0.0670,  ...,  1.8439,  0.3234,  0.0332],\n",
       "          [-1.5988, -0.7036, -0.1286,  ...,  2.6470, -0.7685,  0.4459]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2182, -0.5798,  0.4881,  ..., -0.6620,  1.0653,  0.3167],\n",
       "          [ 0.3106,  1.5705, -1.3217,  ..., -2.4530, -0.4501,  1.4135],\n",
       "          [ 0.3133,  1.9555, -1.4908,  ..., -3.1709, -0.1371,  1.1951],\n",
       "          [-0.5421,  2.5685, -1.4881,  ..., -2.7372, -3.2506,  1.4905]],\n",
       "\n",
       "         [[ 0.2510,  0.5478,  0.5315,  ...,  0.7243,  0.0796,  0.8403],\n",
       "          [-0.5912,  2.0555, -0.5260,  ...,  1.2222,  0.6894,  1.0339],\n",
       "          [ 0.0304,  3.2643,  0.8109,  ..., -1.1886, -1.4854,  0.6145],\n",
       "          [-0.1724,  1.8672,  0.1591,  ...,  0.4926, -1.0445,  1.7736]],\n",
       "\n",
       "         [[-0.7292,  0.3058, -1.5783,  ..., -0.4128,  0.2396, -1.3031],\n",
       "          [-1.9412,  2.3437, -0.1259,  ..., -0.5011,  0.6942,  0.8410],\n",
       "          [-2.7487,  1.8391,  0.2339,  ..., -2.5056,  1.7279,  0.4318],\n",
       "          [-0.0103, -0.9071, -0.2718,  ..., -2.0427, -0.0312,  2.1236]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>), tensor([[[[ 7.3858e-03,  4.4439e-02, -5.4912e-02,  ...,  5.7384e-02,\n",
       "           -5.9930e-02, -9.0681e-02],\n",
       "          [-4.9957e-02,  1.1743e+00,  1.3719e+00,  ..., -8.8204e-01,\n",
       "            1.8336e-01,  7.8185e-01],\n",
       "          [ 5.7391e-02, -1.9477e-01,  5.9818e-02,  ..., -4.6486e-01,\n",
       "           -5.2854e-01,  8.6216e-02],\n",
       "          [ 1.3103e+00,  1.1929e-01,  8.2959e-01,  ..., -1.7386e+00,\n",
       "            9.3081e-02, -8.8603e-02]],\n",
       "\n",
       "         [[ 5.2163e-02, -1.3588e-02,  2.4935e-02,  ..., -4.3389e-02,\n",
       "           -9.8252e-04, -1.3100e-02],\n",
       "          [ 1.3896e-01,  6.8318e-01, -1.1062e+00,  ..., -3.9849e-01,\n",
       "            2.3889e-01, -8.4253e-02],\n",
       "          [ 1.1528e+00,  1.7047e+00,  8.1221e-01,  ..., -1.1704e+00,\n",
       "            3.5670e-01, -9.5442e-01],\n",
       "          [-7.5654e-03, -3.8982e-01, -5.4415e-02,  ..., -9.4984e-01,\n",
       "           -6.1863e-01, -3.8189e-01]],\n",
       "\n",
       "         [[-1.9468e-02,  1.6760e-02, -4.4327e-02,  ...,  1.0048e-02,\n",
       "            3.5292e-02,  6.2993e-02],\n",
       "          [-1.2264e+00, -2.0697e-01,  1.2838e+00,  ...,  1.2102e+00,\n",
       "           -1.5824e+00, -1.2251e+00],\n",
       "          [-2.2911e-01,  2.2697e-02, -2.7595e-01,  ..., -1.3083e+00,\n",
       "           -6.0551e-01,  1.1490e+00],\n",
       "          [-2.4101e-01,  7.0661e-01,  5.8191e-01,  ...,  3.3655e-02,\n",
       "           -1.0040e+00,  1.1314e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.9958e-02,  4.1483e-02,  1.6078e-02,  ..., -4.3333e-02,\n",
       "           -1.0599e-02,  2.8056e-02],\n",
       "          [-7.8255e-01,  1.3628e+00,  1.4015e+00,  ...,  8.9205e-01,\n",
       "           -1.1525e+00,  3.3030e+00],\n",
       "          [-1.3499e+00,  5.4527e-01,  5.4338e-01,  ...,  9.0673e-01,\n",
       "            1.6633e-01,  5.3759e-01],\n",
       "          [-6.8602e-01,  8.7954e-02,  7.8241e-01,  ...,  2.6661e-01,\n",
       "           -3.4379e-01,  6.8330e-01]],\n",
       "\n",
       "         [[ 7.7881e-02,  1.1975e-02,  4.6378e-02,  ...,  4.3138e-02,\n",
       "            3.1153e-02,  3.5621e-02],\n",
       "          [ 1.7626e+00,  8.6994e-01, -6.2692e-01,  ...,  5.8033e-01,\n",
       "            1.9738e-01, -7.3803e-01],\n",
       "          [-1.1346e+00, -1.6346e+00,  1.3593e+00,  ..., -1.1557e-01,\n",
       "            2.1378e+00, -4.6759e-01],\n",
       "          [ 8.8912e-02,  3.7170e-01, -1.7732e+00,  ..., -3.8441e-01,\n",
       "            2.1476e+00,  1.5479e+00]],\n",
       "\n",
       "         [[-1.1037e-01,  2.0434e-02, -5.5880e-02,  ..., -1.0208e-01,\n",
       "            7.1948e-02, -4.2690e-03],\n",
       "          [ 1.4173e-01, -7.6461e-01, -5.8355e-01,  ..., -2.2225e-01,\n",
       "           -2.2723e-01, -6.6092e-01],\n",
       "          [-7.7687e-02,  2.5828e-02, -6.1024e-01,  ..., -3.7363e-01,\n",
       "            8.2958e-01, -5.0217e-01],\n",
       "          [ 5.9642e-01,  2.3400e-01,  6.8461e-02,  ..., -1.8558e+00,\n",
       "           -1.4030e-02,  7.8989e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-1.7261e+00, -3.0454e-01, -3.1631e-01,  ...,  1.7958e-01,\n",
       "            3.3081e-01, -5.0938e-01],\n",
       "          [ 8.9790e-02,  2.1746e-01,  6.6951e-02,  ...,  1.8588e+00,\n",
       "           -1.4911e+00, -3.5149e-01],\n",
       "          [ 6.1313e-01, -8.8295e-02,  6.2603e-01,  ...,  1.4817e+00,\n",
       "           -4.1583e-01,  5.3894e-01],\n",
       "          [ 1.1412e+00, -3.6878e-02, -1.1791e+00,  ...,  1.8680e+00,\n",
       "           -1.0183e+00, -4.1630e-01]],\n",
       "\n",
       "         [[ 1.3317e-01, -8.0265e-02,  2.2963e+00,  ...,  2.1889e-01,\n",
       "            9.0214e-02, -1.9602e-01],\n",
       "          [ 6.9634e-01, -7.7311e-01, -3.7308e-01,  ...,  3.5552e-01,\n",
       "           -1.0668e-01, -8.5954e-01],\n",
       "          [ 2.1557e-01, -6.4067e-01, -1.0518e+00,  ...,  1.1849e+00,\n",
       "           -9.6712e-01, -9.9149e-01],\n",
       "          [ 4.8917e-01, -1.9404e+00, -1.0264e-02,  ..., -4.5743e-01,\n",
       "           -2.0749e-01, -5.6584e-01]],\n",
       "\n",
       "         [[-1.8433e-01,  1.0323e+00,  4.6187e-01,  ..., -5.5118e-01,\n",
       "            3.1582e-01, -1.1468e-01],\n",
       "          [-1.0705e+00, -5.1665e-01,  3.2156e-01,  ...,  7.4503e-01,\n",
       "           -1.6712e-01, -9.3033e-02],\n",
       "          [ 1.2394e-01, -2.4365e-01,  5.8486e-01,  ...,  1.7290e+00,\n",
       "            1.4884e+00, -2.0350e-01],\n",
       "          [-7.6935e-01, -1.8065e-01,  1.4851e+00,  ...,  4.6225e-01,\n",
       "            1.8932e+00, -5.8761e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.6704e-01,  9.8948e-01, -8.8777e-01,  ..., -7.2196e-01,\n",
       "            6.9625e-01,  8.5416e-01],\n",
       "          [ 5.2362e-01,  1.0278e+00, -1.8143e+00,  ...,  1.7342e-01,\n",
       "           -5.7062e-01, -6.6667e-01],\n",
       "          [-8.2898e-01,  5.2305e-01, -3.5292e-01,  ..., -3.1480e-01,\n",
       "           -1.3814e+00, -3.1412e-01],\n",
       "          [ 2.8028e-01,  1.4859e+00,  3.5519e-01,  ..., -8.8115e-02,\n",
       "            8.2140e-01, -2.6154e-01]],\n",
       "\n",
       "         [[-4.0318e-01,  3.8318e-01,  3.3471e-01,  ...,  7.1769e-01,\n",
       "            2.7976e-02, -9.6116e-02],\n",
       "          [-1.0180e+00,  6.6484e-01, -5.1973e-01,  ...,  1.3927e+00,\n",
       "           -2.5232e-01, -1.3015e-01],\n",
       "          [-1.1370e+00,  2.2163e-02,  1.0582e+00,  ...,  1.7105e+00,\n",
       "           -6.4008e-01,  5.4951e-01],\n",
       "          [ 1.6205e+00,  2.5144e-01,  1.0412e+00,  ...,  6.4979e-01,\n",
       "           -7.3746e-01, -3.0214e-02]],\n",
       "\n",
       "         [[-7.3938e-01,  9.6876e-05,  4.3869e-01,  ..., -1.1383e-01,\n",
       "            2.7939e-02, -5.6513e-02],\n",
       "          [ 1.1220e-01,  3.2418e-01,  1.0283e+00,  ...,  3.2853e-02,\n",
       "           -1.3676e+00,  8.9356e-01],\n",
       "          [-4.4675e-02, -2.4620e-01,  8.4844e-01,  ..., -5.7881e-01,\n",
       "           -1.4408e+00,  4.4465e-01],\n",
       "          [ 2.6785e-02,  7.0774e-01,  1.1327e+00,  ...,  5.6490e-01,\n",
       "           -8.6364e-01, -3.0349e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 8.3649e-02, -1.0081e-01, -1.8094e-01,  ..., -3.0988e-01,\n",
       "            2.4538e-01, -1.3245e-01],\n",
       "          [ 1.1428e+00,  6.7751e-01,  4.6180e-01,  ...,  3.1881e+00,\n",
       "           -1.8780e+00,  1.6085e+00],\n",
       "          [ 3.2339e-01,  1.0933e+00, -1.2644e+00,  ...,  4.0496e+00,\n",
       "           -2.4498e-01,  1.8675e+00],\n",
       "          [ 3.2233e-01,  9.8640e-01,  1.1201e+00,  ...,  2.4766e+00,\n",
       "           -8.6177e-01,  9.1257e-01]],\n",
       "\n",
       "         [[ 1.0949e-01, -2.1031e-02,  3.3308e-02,  ..., -5.2226e-02,\n",
       "           -9.5656e-02,  1.4817e-01],\n",
       "          [ 9.4050e-01, -1.2493e+00, -2.0918e-01,  ..., -3.1666e-01,\n",
       "           -5.3444e-01,  4.3078e-02],\n",
       "          [-3.5785e-01, -5.5009e-01, -8.7970e-01,  ..., -1.1785e+00,\n",
       "           -2.4279e-01, -2.0078e-01],\n",
       "          [-1.5932e+00, -1.4275e+00,  4.3628e-01,  ...,  4.4545e-01,\n",
       "           -1.8357e+00, -4.5132e-01]],\n",
       "\n",
       "         [[ 4.2737e-02,  1.5659e-02, -4.8446e-02,  ...,  3.3610e-02,\n",
       "            2.8020e-02,  7.7330e-02],\n",
       "          [ 6.0498e-02,  1.7836e-01,  9.1743e-01,  ..., -6.9815e-01,\n",
       "            1.6873e+00,  6.2949e-01],\n",
       "          [ 1.9709e+00, -5.4137e-01,  1.1882e+00,  ..., -9.0602e-01,\n",
       "            5.4577e-01,  5.5739e-01],\n",
       "          [ 1.0400e+00, -9.4203e-01, -6.3178e-01,  ..., -1.2011e-01,\n",
       "            1.4323e-01, -3.0493e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.4676e-02, -1.7029e-02,  8.4739e-02,  ...,  3.6439e-02,\n",
       "            1.7561e-02,  3.3891e-02],\n",
       "          [-1.8382e-02, -7.6520e-02, -1.7292e-01,  ...,  6.0415e-01,\n",
       "            2.8593e-01, -8.9234e-01],\n",
       "          [-3.2924e+00,  1.3168e+00,  3.6599e-01,  ..., -6.1392e-01,\n",
       "            1.3004e+00, -1.1285e+00],\n",
       "          [-6.1828e-01,  6.4293e-01,  1.4724e+00,  ..., -8.4259e-01,\n",
       "            2.7628e+00,  7.8887e-01]],\n",
       "\n",
       "         [[-1.7911e-01, -6.5461e-02,  7.5285e-02,  ..., -4.0166e-02,\n",
       "            6.2468e-02, -5.9164e-02],\n",
       "          [-7.4472e-01, -5.9771e-01,  5.0248e-01,  ..., -8.1286e-02,\n",
       "            7.9995e-01,  9.6256e-01],\n",
       "          [ 2.0732e-01, -2.8147e-01, -7.2499e-01,  ...,  7.7968e-02,\n",
       "            1.2389e+00,  2.3292e-01],\n",
       "          [ 5.4203e-02,  4.0248e-02,  1.3341e+00,  ...,  5.4999e-01,\n",
       "            5.8955e-02,  1.5328e+00]],\n",
       "\n",
       "         [[ 1.0343e-01, -1.5840e-01,  1.7211e-01,  ..., -1.3103e-01,\n",
       "           -1.3879e-03, -1.6192e-01],\n",
       "          [-3.0384e-01, -8.4375e-02,  7.2643e-01,  ..., -3.0829e-01,\n",
       "            3.2273e-01, -4.5120e-01],\n",
       "          [-1.1893e+00,  1.4672e+00, -8.8014e-03,  ...,  9.7304e-02,\n",
       "           -4.9122e-01, -1.1124e+00],\n",
       "          [ 1.4229e+00,  2.0356e-01, -9.7019e-01,  ..., -2.1845e-01,\n",
       "           -3.2223e-01, -5.8910e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>))), hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(tokens['input_ids'], attention_mask=tokens['attention_mask'])\n",
    "(output.past_key_values[0][0]).shape\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(262, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' the'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, generated_sequence = torch.max(output.logits, 1)\n",
    "generated_sequence =  generated_sequence[0]\n",
    "\n",
    "print(generated_sequence)\n",
    "\n",
    "text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True, skip_special_tokens=True)\n",
    "# out = (text.strip())\n",
    "text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 50257])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import re\n",
    "import string\n",
    "\n",
    "with open('./trsn.txt', 'w') as f:\n",
    "    f.write(inspect.getsource(model.transformer.forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: tensor([[24446,   502,   703,   284,   307,  3772,    13]], device='cuda:0')\n",
      "1: Tell me how to be happy. How much more I want you.\"\n",
      "The next morning, the first thing he did was put on his robe and walked out of her bedroom with a big grin that said \"I'm so glad!\" It wasn't long before she came back in an angry tone from upstairs telling him it's okay for everyone not named Anna or Elsa as well as all three people who were going through puberty at their age have had sex because they thought what happened could happen again later if\n",
      "\n",
      "\n",
      "2: Tell me how to be happy.\n",
      "A: \"Oh, I'm going through my own problems with the way things are.\" A few days ago we went into a meeting and he said it was very hard for him because of all these issues that were happening in his life as well so if you're like this guy who's trying too much or not doing enough then what can they do? And now there is an issue where people have been getting really angry at us about everything which makes them feel\n",
      "\n",
      "\n",
      "3: Tell me how to be happy.\n",
      "So you've been saying that there's a lot of things about yourself, and I think it really is important for people in your life who are looking at the world as something they should aspire towards or want their own way through: what do we have? How can this happen if all our lives were made by some kind out-of-'real' person with no real knowledge whatsoever?\" said Knebelle Mazzucato from New York City on Sunday\n",
      "\n",
      "\n",
      "4: Tell me how to be happy. I don't know what else you can do.\"\n",
      "\"But the problem is, when we talk about happiness or depression it's really a question of who gets depressed,\" she says as they walk out onto Broadway in New York City on Wednesday evening with their new album \"The World Is Not Enough\". The title track from her latest single features an upbeat melody that sounds like something off-thewall pop music would hear  and yet has nothing at all resembling lyrics\n",
      "\n",
      "\n",
      "5: Tell me how to be happy. How do you feel?\n",
      "The way I'm feeling is that there's a great deal of anxiety in my body right now and it can really cause problems, so let us just say this: we're not going anywhere until our bodies are ready for the new world outside.\"\n",
      "\n",
      "\n",
      "6: Tell me how to be happy.\n",
      "It's not as simple for you, it is so easy and we're all just waiting on your approval that makes this game even better! We want our community members in the right place because I think they deserve a great experience of being with each other at PAX East 2016 (and beyond). So here are some tips about getting started: 1) Be aware when asking questions or writing comments before posting any information online - especially if there aren't enough people who know\n",
      "\n",
      "\n",
      "7: Tell me how to be happy.\n",
      "My parents have been married for over 40 years and we are both in our mid-twenties with a daughter named Charlotte, so they're all expecting their first child soon after that (she's going through puberty). We don't know what happens next but it seems like the best option is simply staying at home as long you can or waiting until your kid comes out of school before giving birth  I'm not sure if this will work well on most people\n",
      "\n",
      "\n",
      "8: Tell me how to be happy.\n",
      "I want you guys to get better, so we can continue this journey together and see what kind of life there is for all those who need it the most right nowso that's where I'm going with my next goal.\"\n",
      "\n",
      "\n",
      "9: Tell me how to be happy.\n",
      "I want you in my life! I don't know what will happen next, but when it comes down for the day or two after that and then all of a sudden there's nothing left well not really right now... no more money because we're still here with our parents (not even talking about this yet) maybe some time is just waiting until tomorrow? Maybe at least one month from today.. And if things aren' going great on their way out\n",
      "\n",
      "\n",
      "10: Tell me how to be happy. What do you think of this new book?\"\n",
      "\"It's an interesting way for a lot more people, especially the younger ones who have grown up with their parents and not been raised in such big cities as London or New York.\"\n",
      "I was surprised at what she said about being able read all over again! \"Well I'm sure that if someone had told them it would take two weeks before they could get home from school because we'd need something like Christmas\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = \"Tell me how to be happy.\"\n",
    "# for i in range(30):\n",
    "\n",
    "tokens=np.array([0])\n",
    "# if(tokens.shape[-1] > 1024):\n",
    "if True:\n",
    "    tokens = torch.tensor([tokenizer.encode(start)]).to(device)\n",
    "\n",
    "    print(\"tokens:\" , tokens)\n",
    "    \n",
    "    # output = model.generate(tokens)\n",
    "    sample_outputs = model.generate(tokens, \n",
    "                                    do_sample=True,   \n",
    "                                    min_length=50, \n",
    "                                    max_length=100,\n",
    "                                    top_k=30,                                 \n",
    "                                    top_p=0.7,        \n",
    "                                    temperature=0.9,\n",
    "                                    repetition_penalty=2.0,\n",
    "                                    num_return_sequences=10\n",
    "                                    )\n",
    "\n",
    "    # print(sample_outputs)\n",
    "\n",
    "    for i, sample_output in enumerate(sample_outputs):\n",
    "        text = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
    "        a = len(start)  \n",
    "        print(\"{}: {}\\n\\n\".format(i+1,  text[:]))\n",
    "\n",
    "    # _, generated_sequence = torch.max(output.logits, 2)\n",
    "    # generated_sequence =  generated_sequence[0]\n",
    "\n",
    "    # print(generated_sequence)\n",
    "\n",
    "    # text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True, skip_special_tokens=True)\n",
    "    # text = (text.strip())\n",
    "    # print(\"Start ||  \", start)\n",
    "    # print(\"text || \", text, '\\n')\n",
    "\n",
    "    # start += \" \" + text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect as i\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    @add_start_docstrings_to_model_forward(GPT2_INPUTS_DOCSTRING)\n",
      "    @add_code_sample_docstrings(\n",
      "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
      "        output_type=BaseModelOutputWithPastAndCrossAttentions,\n",
      "        config_class=_CONFIG_FOR_DOC,\n",
      "    )\n",
      "    def forward(\n",
      "        self,\n",
      "        input_ids: Optional[torch.LongTensor] = None,\n",
      "        past_key_values: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n",
      "        attention_mask: Optional[torch.FloatTensor] = None,\n",
      "        token_type_ids: Optional[torch.LongTensor] = None,\n",
      "        position_ids: Optional[torch.LongTensor] = None,\n",
      "        head_mask: Optional[torch.FloatTensor] = None,\n",
      "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
      "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
      "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
      "        use_cache: Optional[bool] = None,\n",
      "        output_attentions: Optional[bool] = None,\n",
      "        output_hidden_states: Optional[bool] = None,\n",
      "        return_dict: Optional[bool] = None,\n",
      "    ) -> Union[Tuple, BaseModelOutputWithPastAndCrossAttentions]:\n",
      "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
      "        output_hidden_states = (\n",
      "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
      "        )\n",
      "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
      "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "\n",
      "        if input_ids is not None and inputs_embeds is not None:\n",
      "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
      "        elif input_ids is not None:\n",
      "            self.warn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n",
      "            input_shape = input_ids.size()\n",
      "            input_ids = input_ids.view(-1, input_shape[-1])\n",
      "            batch_size = input_ids.shape[0]\n",
      "        elif inputs_embeds is not None:\n",
      "            input_shape = inputs_embeds.size()[:-1]\n",
      "            batch_size = inputs_embeds.shape[0]\n",
      "        else:\n",
      "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
      "\n",
      "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
      "\n",
      "        if token_type_ids is not None:\n",
      "            token_type_ids = token_type_ids.view(-1, input_shape[-1])\n",
      "\n",
      "        if past_key_values is None:\n",
      "            past_length = 0\n",
      "            past_key_values = tuple([None] * len(self.h))\n",
      "        else:\n",
      "            past_length = past_key_values[0][0].size(-2)\n",
      "        if position_ids is None:\n",
      "            position_ids = torch.arange(past_length, input_shape[-1] + past_length, dtype=torch.long, device=device)\n",
      "            position_ids = position_ids.unsqueeze(0)\n",
      "\n",
      "        # GPT2Attention mask.\n",
      "        if attention_mask is not None:\n",
      "            if batch_size <= 0:\n",
      "                raise ValueError(\"batch_size has to be defined and > 0\")\n",
      "            attention_mask = attention_mask.view(batch_size, -1)\n",
      "            # We create a 3D attention mask from a 2D tensor mask.\n",
      "            # Sizes are [batch_size, 1, 1, to_seq_length]\n",
      "            # So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\n",
      "            # this attention mask is more simple than the triangular masking of causal attention\n",
      "            # used in OpenAI GPT, we just need to prepare the broadcast dimension here.\n",
      "            attention_mask = attention_mask[:, None, None, :]\n",
      "\n",
      "            # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
      "            # masked positions, this operation will create a tensor which is 0.0 for\n",
      "            # positions we want to attend and the dtype's smallest value for masked positions.\n",
      "            # Since we are adding it to the raw scores before the softmax, this is\n",
      "            # effectively the same as removing these entirely.\n",
      "            attention_mask = attention_mask.to(dtype=self.dtype)  # fp16 compatibility\n",
      "            attention_mask = (1.0 - attention_mask) * torch.finfo(self.dtype).min\n",
      "\n",
      "        # If a 2D or 3D attention mask is provided for the cross-attention\n",
      "        # we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
      "        if self.config.add_cross_attention and encoder_hidden_states is not None:\n",
      "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
      "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
      "            if encoder_attention_mask is None:\n",
      "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n",
      "            encoder_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
      "        else:\n",
      "            encoder_attention_mask = None\n",
      "\n",
      "        # Prepare head mask if needed\n",
      "        # 1.0 in head_mask indicate we keep the head\n",
      "        # attention_probs has shape bsz x n_heads x N x N\n",
      "        # head_mask has shape n_layer x batch x n_heads x N x N\n",
      "        head_mask = self.get_head_mask(head_mask, self.config.n_layer)\n",
      "\n",
      "        if inputs_embeds is None:\n",
      "            inputs_embeds = self.wte(input_ids)\n",
      "        position_embeds = self.wpe(position_ids)\n",
      "        hidden_states = inputs_embeds + position_embeds\n",
      "\n",
      "        if token_type_ids is not None:\n",
      "            token_type_embeds = self.wte(token_type_ids)\n",
      "            hidden_states = hidden_states + token_type_embeds\n",
      "\n",
      "        hidden_states = self.drop(hidden_states)\n",
      "\n",
      "        output_shape = (-1,) + input_shape[1:] + (hidden_states.size(-1),)\n",
      "\n",
      "        if self.gradient_checkpointing and self.training:\n",
      "            if use_cache:\n",
      "                logger.warning_once(\n",
      "                    \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
      "                )\n",
      "                use_cache = False\n",
      "\n",
      "        presents = () if use_cache else None\n",
      "        all_self_attentions = () if output_attentions else None\n",
      "        all_cross_attentions = () if output_attentions and self.config.add_cross_attention else None\n",
      "        all_hidden_states = () if output_hidden_states else None\n",
      "        for i, (block, layer_past) in enumerate(zip(self.h, past_key_values)):\n",
      "            # Model parallel\n",
      "            if self.model_parallel:\n",
      "                torch.cuda.set_device(hidden_states.device)\n",
      "                # Ensure layer_past is on same device as hidden_states (might not be correct)\n",
      "                if layer_past is not None:\n",
      "                    layer_past = tuple(past_state.to(hidden_states.device) for past_state in layer_past)\n",
      "                # Ensure that attention_mask is always on the same device as hidden_states\n",
      "                if attention_mask is not None:\n",
      "                    attention_mask = attention_mask.to(hidden_states.device)\n",
      "                if isinstance(head_mask, torch.Tensor):\n",
      "                    head_mask = head_mask.to(hidden_states.device)\n",
      "            if output_hidden_states:\n",
      "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
      "\n",
      "            if self.gradient_checkpointing and self.training:\n",
      "                outputs = self._gradient_checkpointing_func(\n",
      "                    block.__call__,\n",
      "                    hidden_states,\n",
      "                    None,\n",
      "                    attention_mask,\n",
      "                    head_mask[i],\n",
      "                    encoder_hidden_states,\n",
      "                    encoder_attention_mask,\n",
      "                    use_cache,\n",
      "                    output_attentions,\n",
      "                )\n",
      "            else:\n",
      "                outputs = block(\n",
      "                    hidden_states,\n",
      "                    layer_past=layer_past,\n",
      "                    attention_mask=attention_mask,\n",
      "                    head_mask=head_mask[i],\n",
      "                    encoder_hidden_states=encoder_hidden_states,\n",
      "                    encoder_attention_mask=encoder_attention_mask,\n",
      "                    use_cache=use_cache,\n",
      "                    output_attentions=output_attentions,\n",
      "                )\n",
      "\n",
      "            hidden_states = outputs[0]\n",
      "            if use_cache is True:\n",
      "                presents = presents + (outputs[1],)\n",
      "\n",
      "            if output_attentions:\n",
      "                all_self_attentions = all_self_attentions + (outputs[2 if use_cache else 1],)\n",
      "                if self.config.add_cross_attention:\n",
      "                    all_cross_attentions = all_cross_attentions + (outputs[3 if use_cache else 2],)\n",
      "\n",
      "            # Model Parallel: If it's the last layer for that device, put things on the next device\n",
      "            if self.model_parallel:\n",
      "                for k, v in self.device_map.items():\n",
      "                    if i == v[-1] and \"cuda:\" + str(k) != self.last_device:\n",
      "                        hidden_states = hidden_states.to(\"cuda:\" + str(k + 1))\n",
      "\n",
      "        hidden_states = self.ln_f(hidden_states)\n",
      "\n",
      "        hidden_states = hidden_states.view(output_shape)\n",
      "        # Add last hidden state\n",
      "        if output_hidden_states:\n",
      "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
      "\n",
      "        if not return_dict:\n",
      "            return tuple(\n",
      "                v\n",
      "                for v in [hidden_states, presents, all_hidden_states, all_self_attentions, all_cross_attentions]\n",
      "                if v is not None\n",
      "            )\n",
      "\n",
      "        return BaseModelOutputWithPastAndCrossAttentions(\n",
      "            last_hidden_state=hidden_states,\n",
      "            past_key_values=presents,\n",
      "            hidden_states=all_hidden_states,\n",
      "            attentions=all_self_attentions,\n",
      "            cross_attentions=all_cross_attentions,\n",
      "        )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9439"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.stdout.write(i.getsource(model.transformer.forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: https://www.kaggle.com/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail/download?datasetVersionNumber=2\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.kaggle.com/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail/download?datasetVersionNumber=2 -P /scratch/aneesh.chavan/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-10 16:51:16--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
      "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.109.153, 185.199.111.153, 185.199.108.153, ...\n",
      "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.109.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 42123633 (40M) [application/json]\n",
      "Saving to: /scratch/aneesh.chavan/datasets/train-v2.0.json\n",
      "\n",
      "train-v2.0.json     100%[===================>]  40.17M  14.7MB/s    in 2.7s    \n",
      "\n",
      "2023-11-10 16:51:22 (14.7 MB/s) - /scratch/aneesh.chavan/datasets/train-v2.0.json saved [42123633/42123633]\n",
      "\n",
      "--2023-11-10 16:51:23--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
      "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.110.153, 185.199.108.153, 185.199.111.153, ...\n",
      "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.110.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4370528 (4.2M) [application/json]\n",
      "Saving to: /scratch/aneesh.chavan/datasets/dev-v2.0.json\n",
      "\n",
      "dev-v2.0.json       100%[===================>]   4.17M  6.27MB/s    in 0.7s    \n",
      "\n",
      "2023-11-10 16:51:24 (6.27 MB/s) - /scratch/aneesh.chavan/datasets/dev-v2.0.json saved [4370528/4370528]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !mkdir\n",
    "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json -P /scratch/aneesh.chavan/datasets\n",
    "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json -P /scratch/aneesh.chavan/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "with open(\"/scratch/aneesh.chavan/datasets/train-v2.0.json\", 'r') as f:\n",
    "    squad_train_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'paragraphs'])\n",
      "{'qas': [{'question': 'When did Beyonce start becoming popular?', 'id': '56be85543aeaaa14008c9063', 'answers': [{'text': 'in the late 1990s', 'answer_start': 269}], 'is_impossible': False}, {'question': 'What areas did Beyonce compete in when she was growing up?', 'id': '56be85543aeaaa14008c9065', 'answers': [{'text': 'singing and dancing', 'answer_start': 207}], 'is_impossible': False}, {'question': \"When did Beyonce leave Destiny's Child and become a solo singer?\", 'id': '56be85543aeaaa14008c9066', 'answers': [{'text': '2003', 'answer_start': 526}], 'is_impossible': False}, {'question': 'In what city and state did Beyonce  grow up? ', 'id': '56bf6b0f3aeaaa14008c9601', 'answers': [{'text': 'Houston, Texas', 'answer_start': 166}], 'is_impossible': False}, {'question': 'In which decade did Beyonce become famous?', 'id': '56bf6b0f3aeaaa14008c9602', 'answers': [{'text': 'late 1990s', 'answer_start': 276}], 'is_impossible': False}, {'question': 'In what R&B group was she the lead singer?', 'id': '56bf6b0f3aeaaa14008c9603', 'answers': [{'text': \"Destiny's Child\", 'answer_start': 320}], 'is_impossible': False}, {'question': 'What album made her a worldwide known artist?', 'id': '56bf6b0f3aeaaa14008c9604', 'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}], 'is_impossible': False}, {'question': \"Who managed the Destiny's Child group?\", 'id': '56bf6b0f3aeaaa14008c9605', 'answers': [{'text': 'Mathew Knowles', 'answer_start': 360}], 'is_impossible': False}, {'question': 'When did Beyonc rise to fame?', 'id': '56d43c5f2ccc5a1400d830a9', 'answers': [{'text': 'late 1990s', 'answer_start': 276}], 'is_impossible': False}, {'question': \"What role did Beyonc have in Destiny's Child?\", 'id': '56d43c5f2ccc5a1400d830aa', 'answers': [{'text': 'lead singer', 'answer_start': 290}], 'is_impossible': False}, {'question': 'What was the first album Beyonc released as a solo artist?', 'id': '56d43c5f2ccc5a1400d830ab', 'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}], 'is_impossible': False}, {'question': 'When did Beyonc release Dangerously in Love?', 'id': '56d43c5f2ccc5a1400d830ac', 'answers': [{'text': '2003', 'answer_start': 526}], 'is_impossible': False}, {'question': 'How many Grammy awards did Beyonc win for her first solo album?', 'id': '56d43c5f2ccc5a1400d830ad', 'answers': [{'text': 'five', 'answer_start': 590}], 'is_impossible': False}, {'question': \"What was Beyonc's role in Destiny's Child?\", 'id': '56d43ce42ccc5a1400d830b4', 'answers': [{'text': 'lead singer', 'answer_start': 290}], 'is_impossible': False}, {'question': \"What was the name of Beyonc's first solo album?\", 'id': '56d43ce42ccc5a1400d830b5', 'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}], 'is_impossible': False}], 'context': 'Beyonc Giselle Knowles-Carter (/bijnse/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyonc\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'}\n",
      "dict_keys(['qas', 'context'])\n",
      "{'question': 'When did Beyonce start becoming popular?', 'id': '56be85543aeaaa14008c9063', 'answers': [{'text': 'in the late 1990s', 'answer_start': 269}], 'is_impossible': False}\n",
      "dict_keys(['question', 'id', 'answers', 'is_impossible'])\n"
     ]
    }
   ],
   "source": [
    "# squad has multiple topics,\n",
    "\"\"\"\n",
    "- title\n",
    "- data array of {}\n",
    "    - qas - array of {}\n",
    "        - question\n",
    "        - id\n",
    "        - answers array of {}\n",
    "            - text\n",
    "            - answer start\n",
    "        - is_impossible\n",
    "    - context - string\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for d in squad_train_json[\"data\"]:\n",
    "    print(d.keys())\n",
    "    for q in d[\"paragraphs\"]:\n",
    "        print(q)\n",
    "        print(q.keys())\n",
    "        \n",
    "        qas = q[\"qas\"]\n",
    "\n",
    "        print(qas[0])\n",
    "        print(qas[0].keys())\n",
    "        break\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "droid-slam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
